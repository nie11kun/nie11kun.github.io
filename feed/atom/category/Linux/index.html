<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"
xmlns:thr="http://purl.org/syndication/thread/1.0"
xml:lang="zh-CN"
xml:base="https://blog.niekun.net/category/Linux/"
>
<title type="text">Marco Nie - Linux</title>
<subtitle type="text"></subtitle>
<updated>2023-06-05T16:54:00+08:00</updated>
<generator uri="http://typecho.org/" version="1.2.0">Typecho</generator>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/category/Linux/" />
<id>https://blog.niekun.net/feed/atom/category/Linux/</id>
<link rel="self" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" />
<entry>
<title type="html"><![CDATA[Linux 创建新用户并授予 root]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2822.html" />
<id>https://blog.niekun.net/archives/2822.html</id>
<updated>2023-06-05T16:54:00+08:00</updated>
<published>2023-06-05T16:54:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[Linux 默认会有一个 root 用户，但日常直接使用 root 有一定安全隐患，所以通常情况下我们习惯于创建一个新用户来登录使用，下面介绍常规的建立流程。建立新用户 vpsadmin：add...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2822.html" xml:lang="zh-CN"><![CDATA[
<p>Linux 默认会有一个 root 用户，但日常直接使用 root 有一定安全隐患，所以通常情况下我们习惯于创建一个新用户来登录使用，下面介绍常规的建立流程。</p><p><strong>建立新用户 vpsadmin：</strong></p><pre><code>adduser vpsadmin
</code></pre><p>输入以上命令后会提示输入用户密码，完成后用户 <strong>vpsadmin</strong> 就建立完成了。</p><p><strong>安装 sudo 功能(sudo 就是在关键时刻，让普通账户临时获得 root 的能力):</strong></p><pre><code>apt update &amp;&amp; apt install sudo
</code></pre><p>把 <strong>vpsadmin</strong> 用户加入 <strong>sudo</strong> 名单里:</p><pre><code>visudo
</code></pre><p>执行后会打开相关配置文件，在 <code># User privilege specification</code> 栏后加入一行配置即可：</p><pre><code># User privilege specification

vpsadmin ALL=(ALL) NOPASSWD: ALL</code></pre><p>注意以上配置中 <code>NOPASSWD</code> 的意思是在使用 <strong>root</strong> 权限的时候无需输入 <strong>root</strong> 密码，这样在使用中可以不用频繁的输入密码。如果你想要遵循常规的使用 <code>sudo</code> 时都输入密码，将配置改为：<code>vpsadmin ALL=(ALL:ALL) ALL</code> 即可。</p><p>重新登录用户即可完成配置查看效果。</p><p>参考链接：<br><a href="https://xtls.github.io/document/level-0/ch04-security.html">安全防护篇</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2822.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[Ubuntu 安装 FTP server]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2769.html" />
<id>https://blog.niekun.net/archives/2769.html</id>
<updated>2022-09-16T09:28:45+08:00</updated>
<published>2022-09-16T09:28:45+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[虽然平时可以用 sftp 或 webdav 代替，但是有些时候客户端只支持 ftp 链接，所以介绍下在服务器上安装 ftp server 的简单方法。系统平台：Ubuntu server 20.04]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2769.html" xml:lang="zh-CN"><![CDATA[
<p>虽然平时可以用 sftp 或 webdav 代替，但是有些时候客户端只支持 ftp 链接，所以介绍下在服务器上安装 ftp server 的简单方法。</p><p>系统平台：Ubuntu server 20.04</p><!--more--><h3>安装 vsftpd</h3><p>主要是通过 vsftpd 实现 ftp 功能的，首先安装：</p><pre><code>apt update &amp;&amp; apt install vsftpd
</code></pre><p>安装好后，vsftpd 会自动启动，可以查看当前运行状态：</p><pre><code>systemctl status vsftpd

● vsftpd.service - vsftpd FTP server
     Loaded: loaded (/lib/systemd/system/vsftpd.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2020-04-27 19:35:30 IST; 13s ago
   Main PID: 54532 (vsftpd)
      Tasks: 1 (limit: 1137)
     Memory: 652.0K
     CGroup: /system.slice/vsftpd.service
             └─54532 /usr/sbin/vsftpd /etc/vsftpd.conf

Apr 27 19:35:30 ubuntu systemd[1]: Starting vsftpd FTP server...
Apr 27 19:35:30 ubuntu systemd[1]: Started vsftpd FTP server.</code></pre><p>设置为开机自动启动：</p><pre><code>systemctl enable vsftpd
</code></pre><h3>创建 ftp 用户</h3><p>默认安装好后，会自动创建一个 ftp 用户，这个用户经过我测试无法登录 ftp 服务，这里我们自己创建一个新用户用于登录 ftp，这里创建用户名为 ftpuser：</p><pre><code>adduser ftpuser
</code></pre><p>期间会提示输入创建用户的密码。</p><p>我们只需要这个新用户登录 ftp 不需要它能够访问 ssh 服务，所以下面我们将这个用户排除在 ssh 用户之外，编辑 <code>/etc/ssh/sshd_config</code> 文件，在最后一行添加以下内容：</p><pre><code>DenyUsers ftpuser</code></pre><p>保存后重启 ssh 服务：</p><pre><code>sudo service sshd restart
</code></pre><h3>ftp 目录及权限</h3><p>我们新建一个用于 ftp 的目录：</p><pre><code>mkdir /home/www/ftp
</code></pre><p>将此目录所有者设置为上面创建的 ftpuser：</p><pre><code>chown -R ftpuser:ftpuser /home/www/ftp
</code></pre><p>默认情况下 ftp 目录的根路径不允许有<strong>写权限</strong>，否则链接的时候会报错，所以我们取消这个文件夹的对应权限：</p><pre><code>chmod a-w /home/www/ftp
</code></pre><p>如果想要上传文件，我们可以在这个文件夹内新建一个文件夹专门用来上传：</p><pre><code>mkdir /home/www/ftp/uploads
</code></pre><p>同样的文件夹所有者为 ftpuser：</p><pre><code>chown -R ftpuser:ftpuser /home/www/ftp/uploads
</code></pre><h3>vsftpd 配置文件</h3><p>vsftpd 配置文件路径为：<code>/etc/vsftpd.conf</code>，打开并修改如下设置，最后一行配置文件中没有的话需要自己创建一下：</p><pre><code>listen=NO
listen_ipv6=YES
anonymous_enable=NO
local_enable=YES
write_enable=YES
local_umask=022
dirmessage_enable=YES
use_localtime=YES
xferlog_enable=YES
connect_from_port_20=YES
chroot_local_user=YES
secure_chroot_dir=/var/run/vsftpd/empty
pam_service_name=vsftpd

local_root=/home/www/ftp</code></pre><p>修改完成后重启服务：</p><pre><code>systemctl restart vsftpd
</code></pre><p>此时就可以使用 ftp 客户端连接到 ftp 服务器了。</p><p>为了更加安全，推荐配置 ssl 证书，可以参考：<a href="https://devanswers.co/install-ftp-server-vsftpd-ubuntu-20-04/#id-7-secure-ftp-with-tls-recommended">Secure FTP with TLS (Recommended)</a></p><p>以上就是 ftp server 的简单安装及配置教程。</p><h3>参考链接</h3><p><a href="https://devanswers.co/install-ftp-server-vsftpd-ubuntu-20-04/">How To Install an FTP server (vsftpd) on Ubuntu 20.04/20.10</a><br><a href="https://ubuntu.com/server/docs/service-ftp">FTP Server</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2769.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[Miniflux 搭建自己的 RSS 服务系统]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2749.html" />
<id>https://blog.niekun.net/archives/2749.html</id>
<updated>2022-08-12T14:50:00+08:00</updated>
<published>2022-08-12T14:50:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[一直在使用 feedly 作为 rss 订阅器阅读文章，基本可以满足我的需求，但是部分站点只能预览摘要，想要阅读全文还打开文章链接。最近发现一个开源免费的 rss 系统，他的特点就是轻量无多于内...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2749.html" xml:lang="zh-CN"><![CDATA[
<p>一直在使用 feedly 作为 rss 订阅器阅读文章，基本可以满足我的需求，但是部分站点只能预览摘要，想要阅读全文还打开文章链接。最近发现一个开源免费的 rss 系统，他的特点就是轻量无多于内容，致力于阅读体验。同时我发现他的一些独有功能，可以在文章只显示摘要时，有一个下载全文的选项，这样就实现了大部分文章在 rss 阅读器中就可以阅读全文的需求了。</p><p>Miniflux 需要自己部署在服务器上，它提供了多种安装方法，最简单的就是 docker 方式，避免手动配置环境及数据库等步骤。</p><p>我的系统环境：Ubuntu server 20.04</p><p>Miniflux 官网：<a href="https://miniflux.app/">https://miniflux.app/</a><br>GitHub 主页：<a href="https://github.com/miniflux/v2">https://github.com/miniflux/v2</a></p><!--more--><h3>安装</h3><p>这里介绍通过 docker compose 安装的方法，关于 docker 环境的部署参考我的教程：<a href="https://blog.niekun.net/archives/2742.html#title-1">https://blog.niekun.net/archives/2742.html#title-1</a></p><p>新建 miniflux 文件夹用来放置相关配置：</p><pre><code>mkdir miniflux
cd miniflux
</code></pre><p>然后建立 docker-compose.yml 配置文件，内容如下：</p><pre><code>version: '3.4'
services:
  miniflux:
    image: ${MINIFLUX_IMAGE:-miniflux/miniflux:latest}
    container_name: miniflux
    restart: always
    ports:
      - &quot;18080:8080&quot;
    depends_on:
      - db
    environment:
      - DATABASE_URL=postgres://miniflux:secret@db/miniflux?sslmode=disable
      - BASE_URL=https://miniflux.your.domain
      - RUN_MIGRATIONS=1
      - CREATE_ADMIN=1
      - ADMIN_USERNAME=admin
      - ADMIN_PASSWORD=test123
      - DEBUG=1
    # Optional health check:
    # healthcheck:
    #  test: [&quot;CMD&quot;, &quot;/usr/bin/miniflux&quot;, &quot;-healthcheck&quot;, &quot;auto&quot;]
  db:
    image: postgres:latest
    container_name: postgres
    restart: always
    environment:
      - POSTGRES_USER=miniflux
      - POSTGRES_PASSWORD=secret
    volumes:
      - miniflux-db:/var/lib/postgresql/data
    healthcheck:
      test: [&quot;CMD&quot;, &quot;pg_isready&quot;, &quot;-U&quot;, &quot;miniflux&quot;]
      interval: 10s
      start_period: 30s
volumes:
  miniflux-db:</code></pre><p>其中需要自行根据实际情况修改一些内容：</p><ul><li>port 端口的主机映射，这里我使用了 18080 映射容器内的 8080 端口</li><li>BASE_URL 设置需要访问 miniflux 服务的域名地址，后面需要配置反向代理</li><li>ADMIN_USERNAME 设置管理员用户名</li><li>ADMIN_PASSWORD  设置管理员用户密码</li></ul><p>敏感的环境变量值可以单独放在同配置文件路径下的 <code>.env</code> 文件中，上面的 docker 安装教程中有介绍。</p><p>注意 DATABASE_URL 地址中的 postgres 用户名密码对应于 POSTGRES_USER 和 POSTGRES_PASSWORD 的值，需要保持一致。</p><p>然后就可以启动容器：</p><pre><code>docker-compose up -d
</code></pre><h3>反代配置</h3><p>首先如果需要解析到二级域名下，先要在 ns 服务端添加二级域名的 A 记录，然后才能正常解析 url。</p><p>使用域名访问 miniflux 服务，需要通过主机使用的反代软件配置解析，我服务器使用的是 nginx，下面介绍配置方法。</p><p>给 nginx 配置添加如下内容：</p><pre><code>server {
    listen        443 ssl http2;
    listen        [::]:443 ssl http2;
    server_name   miniflux.your.domain;
    include       my-server/ssl;

    location / {
        proxy_pass          http://127.0.0.1:18080;
        proxy_redirect      off;

        proxy_set_header    Host              $host;
        proxy_set_header    X-Forwarded-Host  $host;
        proxy_set_header    X-Real-IP         $remote_addr;
        proxy_set_header    X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header    X-Forwarded-Proto $scheme;
        proxy_set_header    Upgrade           $http_upgrade;
        proxy_set_header    Connection        &quot;upgrade&quot;;
        proxy_http_version  1.1;
    }
}</code></pre><p>以上配置需要根据实际情况修改监听端口及 domain，由于之前配置的 miniflux 的映射端口是 18080，所以反代到本地的对应端口即可。</p><p>以上 miniflux 和 nginx 反代配置完成后应该就可以访问 <a href="https://miniflux.your.domain">https://miniflux.your.domain</a> 了。用户名密码就是 docker 配置文件中定义的管理员账户及密码：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/4289742324.png" alt="2022-08-12T06:47:50.png" title="2022-08-12T06:47:50.png"></p><h3>使用</h3><p>如果某一篇文章不显示全文，只需要点击文章顶部的 download 按钮即可加载全文：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/966087234.png" alt="2022-08-12T06:47:12.png" title="2022-08-12T06:47:12.png"></p><p>miniflux 提供了丰富的 api 接口可供二次开发使用，通过简单的请求就可以获取到文章的各种信息，返回数据为 json 格式。</p><p>官方 api 文档参考：<a href="https://miniflux.app/docs/api.html">https://miniflux.app/docs/api.html</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2749.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[自建 RustDesk server]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2744.html" />
<id>https://blog.niekun.net/archives/2744.html</id>
<updated>2022-08-07T14:08:00+08:00</updated>
<published>2022-08-07T14:08:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[RustDesk 是一款开源的跨平台远程桌面软件，类似于 TeamViewer 的 UI 样式，但它是完全免费的。RustDesk 提供了 3 个免费的转发服务器，会根据你的地理位置自动选择最快...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2744.html" xml:lang="zh-CN"><![CDATA[
<p>RustDesk 是一款开源的跨平台远程桌面软件，类似于 TeamViewer 的 UI 样式，但它是完全免费的。</p><p>RustDesk 提供了 3 个免费的转发服务器，会根据你的地理位置自动选择最快的，一般使用足够了，如果对安全性有担忧，它们也提供了 server 端应用，可以自建转发服务器。下面就对搭建 server 端做一些介绍。</p><p>RustDesk GitHub 主页：<a href="https://github.com/rustdesk/rustdesk">https://github.com/rustdesk/rustdesk</a><br>RustDesk Server GitHub 主页：<a href="https://github.com/rustdesk/rustdesk-server">https://github.com/rustdesk/rustdesk-server</a></p><p>服务器平台：ubuntu 20.04</p><!--more--><h3>安装 server</h3><p>我是通过 docker 安装的 server 端，这样最快速简单。</p><p>关于 docker 和 docker compose 的安装可以参考我之前的文章：<a href="https://blog.niekun.net/archives/2742.html#title-1">https://blog.niekun.net/archives/2742.html#title-1</a></p><p><strong>docker-compose.yml</strong> 文件内容如下：</p><pre><code>version: '3'

networks:
  rustdesk-net:
    external: false

services:
  hbbs:
    container_name: hbbs
    ports:
      - 21115:21115
      - 21116:21116
      - 21116:21116/udp
      - 21118:21118
    image: rustdesk/rustdesk-server:latest
    command: hbbs -r xxx.xxx.xxx.xxx:21117
    volumes:
      - ./data:/root
    networks:
      - rustdesk-net
    depends_on:
      - hbbr
    restart: unless-stopped

  hbbr:
    container_name: hbbr
    ports:
      - 21117:21117
      - 21119:21119
    image: rustdesk/rustdesk-server:latest
    command: hbbr
    volumes:
      - ./data:/root
    networks:
      - rustdesk-net
    restart: unless-stopped</code></pre><p>这里配置 hbbs IP 地址需要设置为中继服务器的 IP 或域名，否则无法链接。默认监听的是 21117 端口，客户端默认也是链接服务器的这个端口。如果修改这里的默认端口，则在客户端设置的时候也需要指定此端口。</p><p>启动服务：</p><pre><code>docker-compose up -d
</code></pre><p>此时在客户端设置 ID server：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/43407160.jpg" alt="1.jpg" title="1.jpg"></p><p>在第一行填入服务器 IP 地址即可：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/2720143847.jpg" alt="2.jpg" title="2.jpg"></p><p>确认后，如果下方状态栏显示 <strong>ready</strong> 表示服务器链接正常：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/4049467528.jpg" alt="3.jpg" title="3.jpg"></p><h3>配置域名访问</h3><p>如果想要使用域名作为 server id，需要在你的域名服务器里加上一条自定义的域名 NS 解析，如：rust.abc.com。</p><p>注意如果你使用的是 cloudflare 服务，由于它在启用 CDN 后只支持少数端口的转发，而我们需要使用的是 21115 - 21119 这些端口，所以需要在 dns 配置时取消这个自定义域名的<strong>小黄云</strong>，只使用其 dns 服务：<br><img src="https://blog.niekun.net/usr/uploads/2022/08/1547842714.jpg" alt="4.jpg" title="4.jpg"></p><p>关于 cloudflare 的网络端口转发相关的信息参考官网内容：<a href="https://developers.cloudflare.com/fundamentals/get-started/reference/network-ports/">Network ports</a></p><p>自定义域名配置好后，修改 <strong>docker-compose.yml</strong> 配置文件中定义的地址为指定域名：</p><pre><code>command: hbbs -r rust.abc.com:21117
</code></pre><p>重启容器后就可以在客户端的 ID server 中使用域名链接了。方法和上面介绍的用服务器 IP 设置的方法相同。</p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2744.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[Joplin server 搭建]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2742.html" />
<id>https://blog.niekun.net/archives/2742.html</id>
<updated>2022-07-14T08:19:00+08:00</updated>
<published>2022-07-14T08:19:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[joplin 是一款开源笔记应用，全平台适用，支持多种云端同步方式。最近体验了下感觉不错，尤其是可以自行搭建 server 服务端保存数据，适合喜欢管理整个数据流程的人士。下面介绍如何在服务器通...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2742.html" xml:lang="zh-CN"><![CDATA[
<p>joplin 是一款开源笔记应用，全平台适用，支持多种云端同步方式。最近体验了下感觉不错，尤其是可以自行搭建 server 服务端保存数据，适合喜欢管理整个数据流程的人士。下面介绍如何在服务器通过 docker 搭建 joplin server 的方法。</p><p>joplin 官网：<a href="https://joplinapp.org/">https://joplinapp.org/</a><br>GitHub 主页：<a href="https://github.com/laurent22/joplin">https://github.com/laurent22/joplin</a><br>各个平台客户端下载：<a href="https://joplinapp.org/download/">https://joplinapp.org/download/</a></p><p>我的服务器系统平台是 Ubuntu 20.04。</p><!--more--><h3>docker 环境安装</h3><p>首先如果安装过老版的 docker 先卸载:</p><pre><code>sudo apt-get remove docker docker-engine docker.io containerd runc
</code></pre><p>安装基础环境：</p><pre><code> sudo apt-get update
 sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release</code></pre><p>添加 docker 官方 GPG key：</p><pre><code>sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</code></pre><p>安装 docker 和 docker-compose：</p><pre><code> sudo apt-get update
 sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin</code></pre><p>docker 配置为非 root 用户，解决执行命令需要 sudo：</p><pre><code>sudo groupadd docker
sudo usermod -aG docker $USER
su - ${USER}</code></pre><h3>配置 docker-compose</h3><p>通过 docker-compose 可以方便的配置 docker 容器设置及多容器之间数据交互。</p><p>新建 joplin 文件夹用来存放配置 <code>docker-compose.yml</code> 以及 <code>.env</code> 环境变量文件，我喜欢放在 opt 路径下：</p><pre><code>mkdir /opt/docker/joplin
cd /opt/docker/joplin
</code></pre><p>新建环境变量文件 <code>.env</code> 内容如下：</p><pre><code>APP_BASE_URL=https://joplin.your.site
APP_PORT=22300
# 
DB_CLIENT=postgres
POSTGRES_PASSWORD=PASSWORD
POSTGRES_DATABASE=joplin
POSTGRES_USER=USERNAME
POSTGRES_PORT=5432
POSTGRES_HOST=localhost</code></pre><p>上面的配置中需要自行修改几项：</p><ul><li><code>APP_BASE_URL</code> 修改为你实际访问 joplin 服务的外网地址，需要提前配置好 dns 映射，我是通过 cloudflare 管理的</li><li><code>POSTGRES_PASSWORD</code> 修改数据库密码</li><li><code>POSTGRES_USER</code> 修改数据库用户名</li></ul><p>新建 <code>docker-compose.yml</code> 内容如下：</p><pre><code>version: '3'
services:
    db:
        image: postgres:13
        volumes:
            - ./data/postgres:/var/lib/postgresql/data
        ports:
            - &quot;5432:5432&quot;
        restart: unless-stopped
        environment:
            - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
            - POSTGRES_USER=${POSTGRES_USER}
            - POSTGRES_DB=${POSTGRES_DATABASE}
        network_mode: host
    app:
        image: joplin/server:latest
        depends_on:
            - db
        ports:
            - &quot;22300:22300&quot;
        restart: unless-stopped
        environment:
            - APP_PORT=${APP_PORT}
            - APP_BASE_URL=${APP_BASE_URL}
            - DB_CLIENT=${DB_CLIENT}
            - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
            - POSTGRES_DATABASE=${POSTGRES_DATABASE}
            - POSTGRES_USER=${POSTGRES_USER}
            - POSTGRES_PORT=${POSTGRES_PORT}
            - POSTGRES_HOST=${POSTGRES_HOST}
        network_mode: host</code></pre><p>docker-compose 会自动调用同一路径下的 <code>.env</code> 文件中定义的环境变量。</p><p>完成配置后启动容器：</p><pre><code>docker-compose up -d
</code></pre><h3>nginx 配置</h3><p>外网访问上面定义的 url 后，需要通过反向代理将数据流传给 joplin server 端口 22300，我使用的是 nginx 配置如下：</p><pre><code>server {
    listen        443 ssl http2;
    listen        [::]:443 ssl http2;
    server_name   joplin.your.site;
    include       my-server/ssl; 加入 ssl 相关配置

    location / {
        proxy_pass          http://127.0.0.1:22300;
        proxy_redirect      off;

        proxy_set_header    Host              $host;
        proxy_set_header    X-Real-IP         $remote_addr;
        proxy_set_header    X-Forwarded-For   $proxy_add_x_forwarded_for;
        proxy_set_header    X-Forwarded-Proto $scheme;
        proxy_set_header    Upgrade           $http_upgrade;
        proxy_set_header    Connection        &quot;upgrade&quot;;
        proxy_http_version  1.1;
    }
}</code></pre><p>完成后重启 nginx：</p><pre><code>systemctl restart nginx
</code></pre><h3>访问</h3><p>配置好 docker 和 nginx 后就可以访问上面设置的 url 访问 joplin 了，默认会自动创建一个用户 <strong>admin@localhost</strong>，密码是 <strong>admin</strong>。</p><p>第一次登录进去后最好修改下默认管理员密码，还可以创建多个账户。</p><p>如果要适用账户的邮件服务，需要额外配置 SMTP 相关的内容，这里不做介绍，新建账户的激活邮件可以在管理菜单中找到，没有配置邮件服务的话无法发送成功，可以手动将邮件中的账户激活链接发送给别人。</p><p>如果登录网址无法访问网页，可能是 docker 配置有问题，可以通过 log 查看是否有报错信息：</p><pre><code>docker container list # 查询到容器的 ID
docker logs ID # 通过 joplin 的容器 ID 查询其日志
</code></pre><h3>插件</h3><p>joplin 桌面版支持安装插件，第三方插件有很多，可以在下面链接查找：<a href="https://github.com/joplin/plugins/blob/master/README.md#plugins">Joplin Plugin Repository</a></p><h3>参考链接</h3><p><a href="https://docs.docker.com/engine/install/ubuntu/">nstall Docker Engine on Ubuntu</a><br><a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-20-04">How To Install and Use Docker on Ubuntu 20.04</a><br><a href="https://docs.docker.com/engine/reference/commandline/logs/">docker logs</a><br><a href="https://github.com/laurent22/joplin/blob/dev/packages/server/README.md">joplin server install</a><br><a href="https://github.com/laurent22/joplin/blob/dev/docker-compose.server.yml">docker-compose.server.yml</a><br><a href="https://github.com/laurent22/joplin/blob/dev/.env-sample">.env-sample</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2742.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[esxi 配置 GPU 显卡直通给虚拟机使用]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2705.html" />
<id>https://blog.niekun.net/archives/2705.html</id>
<updated>2022-05-25T08:56:00+08:00</updated>
<published>2022-05-25T08:56:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[最近在我家里的 Ubuntu 上安装了 jellyfin 媒体中心，发现局域网内播放高码率视频卡顿严重，原因是默认设置的是软解码导致 cpu 负载很高，在设置里可以开启硬件解码，但是配置后发现播...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2705.html" xml:lang="zh-CN"><![CDATA[
<p>最近在我家里的 Ubuntu 上安装了 jellyfin 媒体中心，发现局域网内播放高码率视频卡顿严重，原因是默认设置的是软解码导致 cpu 负载很高，在设置里可以开启硬件解码，但是配置后发现播放视频会报错：</p><blockquote>客户端配置文件存在问题，服务器未发送兼容的媒体格式</blockquote><p>看后台 log 日志，发现在 ffmpeg 解码时有如下报错信息：</p><pre><code>[AVHWDeviceContext @ 0x558b80b15a80] libva: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)
[AVHWDeviceContext @ 0x558b80b15a80] Failed to initialise VAAPI connection: -1 (unknown libva error).
Device creation failed: -5.
Failed to set value 'vaapi=va:/dev/dri/renderD128' for option 'init_hw_device': Input/output error
Error parsing global options: Input/output error</code></pre><!--more--><h3>查找原因</h3><p>测试在 docker-compose.yml 中开启全部权限，配置 root PUID PGID，以及映射 GPU 设备给 docker：</p><pre><code>    environment:
      - PUID=0
      - PGID=0
    devices:
      - /dev/dri:/dev/dri
    privileged: true</code></pre><p>重启容器后依然会报错。</p><p>报错信息显示无法读取 gpu 驱动名称，这应该不是 docker 的问题，在主机上测试 <code>vainfo</code> 也会报错：</p><pre><code>$ vainfo
error: can't connect to X server!
libva info: VA-API version 1.14.0
libva error: vaGetDriverNameByIndex() failed with unknown libva error, driver_name = (null)
vaInitialize failed with error code -1 (unknown libva error),exit</code></pre><p>报错内容和 jellyfin 的日志类似，测试添加环境变量强制指定驱动名称：</p><pre><code>export LIBVA_DRIVER_NAME=iHD</code></pre><p>再次 vainfo：</p><pre><code>$ vainfo
error: can't connect to X server!
libva info: VA-API version 1.14.0
libva info: User environment variable requested driver 'iHD'
libva info: Trying to open /usr/local/lib/dri/iHD_drv_video.so
libva info: Found init function __vaDriverInit_1_14
DRM_IOCTL_I915_GEM_APERTURE failed: Invalid argument
Assuming 131072kB available aperture size.
May lead to reduced performance or incorrect rendering.
get chip id failed: -1 [22]
param: 4, val: 0
libva error: /usr/local/lib/dri/iHD_drv_video.so init failed
libva info: va_openDriver() returns 18
vaInitialize failed with error code 18 (invalid parameter),exit</code></pre><p>现在看来应该是其他问题了，经过查询，esxi 默认是分配了虚拟显卡给虚拟机，导致虚拟机无法调用 gpu 底层的一些功能，从而导致 ffmpeg 等工具硬件解码失效。处理办法就是在 esxi 上配置显卡直通，然后添加给对应虚拟机直接调用硬件资源。</p><p><strong>经过下面的尝试，我还是设置显卡直通，导致最终无法实现硬件解码。可能是主板上有限制吧。</strong></p><h3>显卡直通</h3><p>显卡直通应该就可以解决上面的问题，但是当我直接进入 esxi 控制台设备管理中却找不到 GPU 设备，需要进入 esxi ssh 查看是否有 GPU 设备类似于：<strong>UHD Graphics 630</strong>。</p><p>ssh 登录 esxi 后台，首先查看是否有 GPU相关设备信息，终端命令行执行：</p><pre><code>lspci -v
</code></pre><p>找到显卡设备ID，如图所示：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/3352280738.png" alt="2022-05-25T00:39:59.png" title="2022-05-25T00:39:59.png"></p><p><strong>8086:9bc8</strong> 就是显卡设备 ID，其中 8086 是供应商 ID，也就是代表 Intel，9bc8 就是这块显卡的设备硬件 ID。</p><p>然后关闭 esxi 对 GPU 的调用，然后手动添加 pci 设备信息，然后就可以在控制台配置直通了。</p><p>通过 ssh 登录 esxi，输入如下命令取消显卡占用，注意取消后就不能连接显示器访问 esxi 后台图形界面了：</p><pre><code>esxcli system settings kernel set -s vga -v FALSE</code></pre><p>后期如果需要取消显卡直通或者登录图形后台需要重新开启显卡调用：</p><pre><code>esxcli system settings kernel set -s vga -v TRUE</code></pre><p>然后修改 <strong>passthru.map</strong> 添加 PCIE 设备 ID 信息。</p><p>修改<strong>/etc/vmware/passthru.map</strong> 文件，根据上面找到的设备 ID 信息，在最底部增加以下信息：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/244215120.png" alt="2022-05-25T00:41:31.png" title="2022-05-25T00:41:31.png"></p><p>完成后保存并退出，然后重启 esxi。</p><p>重启完成后就可以从控制台 pci 设备中找到显卡了：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/1706081722.png" alt="2022-05-25T00:42:58.png" title="2022-05-25T00:42:58.png"></p><p>配置好直通后，给对应虚拟机配置显卡。</p><h3>虚拟机配置</h3><p>首先编辑虚拟机，CPU虚拟化这三个选项全部取消，未取消开启虚拟机会报错：由于硬件或软件支持不可用,因此无法为 0:2.0 注册设备 pciPassthru0：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/3232202527.png" alt="2022-05-25T00:44:00.png" title="2022-05-25T00:44:00.png"></p><p>内存勾选<strong>预留所有客户机内存（全部锁定）</strong>选项，不勾选启动虚拟机会报错：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/3432325478.png" alt="2022-05-25T00:44:56.png" title="2022-05-25T00:44:56.png"></p><p>最后添加显卡：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/19783185.png" alt="2022-05-25T00:45:30.png" title="2022-05-25T00:45:30.png"><br><img src="https://blog.niekun.net/usr/uploads/2022/05/3251442515.png" alt="2022-05-25T00:45:40.png" title="2022-05-25T00:45:40.png"></p><p>然后配置虚拟机自定义参数：</p><p>进入<strong>虚拟机选项 → 高级 → 配置参数 → 编辑配置</strong>添加以下参数：</p><table><thead><tr><th align="center"> </th><th align="center"> </th></tr></thead><tbody><tr><td align="center">键</td><td align="center">值</td></tr><tr><td align="center">hypervisor.cpuid.v0</td><td align="center">FALSE</td></tr></tbody></table><p>此参数的作用：不让操作系统识别是在虚拟机环境运行，一般直通独立显卡需要这样设置，核显可忽略，但设置也无妨。</p><p>如下图所示：<br><img src="https://blog.niekun.net/usr/uploads/2022/05/1105053334.png" alt="2022-05-25T00:47:09.png" title="2022-05-25T00:47:09.png"><br><img src="https://blog.niekun.net/usr/uploads/2022/05/1984221498.png" alt="2022-05-25T00:47:24.png" title="2022-05-25T00:47:24.png"><br><img src="https://blog.niekun.net/usr/uploads/2022/05/323988867.png" alt="2022-05-25T00:47:35.png" title="2022-05-25T00:47:35.png"></p><p>由于虚拟机默认有一个虚拟显卡，我们又添加了一个直通显卡，现在就有了两个显卡，但我们只想要直通的显卡工作，可以在配置参数里添加一行:</p><table><thead><tr><th align="center"> </th><th align="center"> </th></tr></thead><tbody><tr><td align="center">键</td><td align="center">值</td></tr><tr><td align="center">svga.present</td><td align="center">FALSE</td></tr></tbody></table><p><img src="https://blog.niekun.net/usr/uploads/2022/05/4078790044.png" alt="2022-05-25T00:52:18.png" title="2022-05-25T00:52:18.png"></p><p>这样操作后，我们开启虚拟机后再 <code>/dev/dri</code> 目录下就只会有一个 renderD128：</p><pre><code>ls -l /dev/dri/

total 0
crw-rw---- 1 root video 226,   0 Oct 23 20:41 card0
crw-rw---- 1 root video 226, 128 Oct 23 20:41 renderD128</code></pre><p>查看 pci 设备信息：</p><pre><code>&lt;&gt; sudo lspci -v -s  04:00.0
04:00.0 VGA compatible controller: Intel Corporation HD Graphics 530 (rev 06) (prog-if 00 [VGA controller])
    Subsystem: Hewlett-Packard Company Device 82bf
    Physical Slot: 161
    Flags: bus master, fast devsel, latency 64, IRQ 67
    Memory at fc000000 (64-bit, non-prefetchable) [size=16M]
    Memory at d0000000 (64-bit, prefetchable) [size=256M]
    I/O ports at 7000 [size=64]
    Expansion ROM at &lt;unassigned&gt; [disabled]
    Capabilities: [40] Vendor Specific Information: Len=0c &lt;?&gt;
    Capabilities: [70] Express Endpoint, MSI 00
    Capabilities: [ac] MSI: Enable+ Count=1/1 Maskable- 64bit-
    Capabilities: [d0] Power Management version 2
    Capabilities: [100] Process Address Space ID (PASID)
    Capabilities: [200] Address Translation Service (ATS)
    Capabilities: [300] Page Request Interface (PRI)
    Kernel driver in use: i915
    Kernel modules: i915</code></pre><p>这样显卡就直接直通给了虚拟机，注意这样配置后包括 esxi 本身和其他虚拟机就没有显卡可用了，导致没有图形界面。</p><h3>参考链接</h3><p><a href="https://nucfans.com/p/4622.html">ESXI 7.02 Intel 核心显卡直通开启3D加速</a><br><a href="https://elatov.github.io/2018/04/esxi-65-passthrough-video-card-to-plex-vm/#disabling-primary-video-card-on-a-vm">ESXi 6.5 Passthrough Video Card/GPU to Plex VM</a><br><a href="https://www.reddit.com/r/PleX/comments/n913ui/hw_transcoding_vaapi_intel_not_working/">HW Transcoding - VAAPI - Intel not working</a><br><a href="https://techzone.vmware.com/resource/deploying-hardware-accelerated-graphics-vmware-horizon-7">Deploying Hardware-Accelerated Graphics with VMware Horizon</a><br><a href="https://www.right.com.cn/forum/thread-4045612-1-1.html">Esxi 6.7核显直通问题求教各位恩山大神</a><br><a href="https://pci-ids.ucw.cz/read/PC/8086/3e91">Name: UHD Graphics 630</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2705.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[Ubuntu 开启 RDP 远程连接]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2703.html" />
<id>https://blog.niekun.net/archives/2703.html</id>
<updated>2022-05-23T10:18:00+08:00</updated>
<published>2022-05-23T10:18:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[之前介绍过通过安装 TightVNC vnc server 远程连接 Ubuntu 桌面的教程，Windows 下常用的是 RDP 方式远程，使用体验非常流畅，不占用带宽。Linux 下也可以通...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2703.html" xml:lang="zh-CN"><![CDATA[
<p>之前介绍过通过安装 TightVNC vnc server 远程连接 Ubuntu 桌面的教程，Windows 下常用的是 RDP 方式远程，使用体验非常流畅，不占用带宽。Linux 下也可以通过安装 Xrdp 的方式实现 rdp 连接。</p><p>参考教程：<a href="https://blog.niekun.net/archives/2281.html">Ubuntu desktop 配置 vnc server</a></p><!--more--><p>xrdp 是对 Windows rdp 协议的开源实现。</p><h3>安装</h3><p>我的系统是 Ubuntu desktop 20.04，首先需要保证有一个已经安装的桌面环境，desktop 版默认是 genome，也可以安装其他的如 xfce：</p><pre><code>sudo apt install ubuntu-desktop</code></pre><p>安装 xrdp：</p><pre><code>sudo apt install xrdp</code></pre><p>安装完成后，xrdp 会自动启动，可以通过命令查看状态：</p><pre><code>$  sudo systemctl status xrdp
 
● xrdp.service - xrdp daemon
     Loaded: loaded (/lib/systemd/system/xrdp.service; enabled; vendor preset: enabled)
     Active: active (running) since Mon 2022-05-23 09:50:43 CST; 20min ago
       Docs: man:xrdp(8)
             man:xrdp.ini(5)
    Process: 83586 ExecStartPre=/bin/sh /usr/share/xrdp/socksetup (code=exited, status=0/SUCCESS)
    Process: 83594 ExecStart=/usr/sbin/xrdp $XRDP_OPTIONS (code=exited, status=0/SUCCESS)
   Main PID: 83595 (xrdp)
      Tasks: 2 (limit: 9459)
     Memory: 26.4M
     CGroup: /system.slice/xrdp.service
             ├─83595 /usr/sbin/xrdp
             └─83597 /usr/sbin/xrdp</code></pre><p>默认 rdp 端口为 3389.</p><h3>配置</h3><p>xrdp 安装后，会自动创建一个新系统用户 <code>xrdp</code>，并且将一个 ssl key <code>ssl-cert-snakeoil.key</code> 放入 <code>/etc/ssl/private/</code> 文件夹，需要将 xrdp 用户添加到 ssl-cert 用户组确保 xrdp 可以读取这个 ssl key：</p><pre><code>sudo adduser xrdp ssl-cert</code></pre><p>默认配置测试访问会有黑屏问题，显示不出来界面，需要修改 <code>/etc/xrdp/startwm.sh</code> 文件，在文件最后的 <code>test -x /etc/X11/Xsession</code> 前面加入如下内容：</p><pre><code>unset DBUS_SESSION_BUS_ADDRESS
unset XDG_RUNTIME_DIR</code></pre><p>重启 xrdp 服务：</p><pre><code>sudo systemctl restart xrdp</code></pre><p>现在就可以正常通过 rdp 连接到 Ubuntu了。</p><p>在使用中，我出现了输入用户密码后停留在解锁界面无法登录进去的问题，经过查询 xdrp 目前不可以同时在多个设备上尝试登录。同时登录 xrdp 的用户如果和正常在主机上登录的是同一个用户，需要删除 <code>dbus-user-session</code> 包，用 <code>dbus-x11</code> 代替。第三点，需要保证 gdm3 运行，执行下面的命令：</p><pre><code>sudo apt remove dbus-user-session
sudo apt install dbus-x11

sudo systemctl set-default graphical
sudo systemctl isolate graphical</code></pre><p>重启 xrdp 服务：</p><pre><code>sudo systemctl restart xrdp</code></pre><p>此时应该就可以正常通过 rdp 客户端链接 ubuntu 界面了。</p><p>但是我测试发现，第一次登录进去没问题，关闭后过一会儿再次尝试链接发现卡在登录界面没反应了，尝试执行如下命令：</p><pre><code>echo xfce4-session &gt; $HOME/.xsession
chmod +x .xsession</code></pre><p>发现问题似乎解决了，但是调用的事 xfce 桌面环境。</p><h3>远程登录</h3><p>在局域网下访问比较流畅，但是在外网下发现没法达到 Windows rdp 流畅的效果。解决方法可以是在外网通过 rdp 链接一个局域网下 Windows 设备，然后在 Windows 设备下通过 rdp 链接局域网内的 ubuntu 设备。</p><h3>参考链接</h3><p><a href="https://www.tecmint.com/install-xrdp-on-ubuntu/">How to Install Xrdp on Ubuntu 20.04</a><br><a href="https://github.com/neutrinolabs/xrdp/issues/1795#issuecomment-859471779">Xrdp stuck on login, after password is entered, unblocked if I unlock from the ubuntu rdp server</a><br><a href="https://github.com/neutrinolabs/xrdp/wiki/Debian-dbus-user-session-package">Using the console and XRDP together in Debian / Ubuntu / Mint</a><br><a href="https://github.com/neutrinolabs/xrdp/issues/1412#issuecomment-730311330">XRDP session immediately closes after loggin in</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2703.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[systemd 服务加载 env 环境变量]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2621.html" />
<id>https://blog.niekun.net/archives/2621.html</id>
<updated>2022-04-11T11:21:00+08:00</updated>
<published>2022-04-11T11:21:00+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[最近在测试中发现，通过 systemd service 启动的 python 脚本无法加载系统 bashrc 内定义的环境变量。需要在 uint 中定义自定义环境变量才能生效。首先建立自定义环境...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2621.html" xml:lang="zh-CN"><![CDATA[
<p>最近在测试中发现，通过 systemd service 启动的 python 脚本无法加载系统 bashrc 内定义的环境变量。需要在 uint 中定义自定义环境变量才能生效。</p><p>首先建立自定义环境变量文件，如： <code>/etc/env_addon</code>，其中定义需要的环境变量：</p><pre><code>ENV1=abcd
ENV2=5678</code></pre><p>然后在 unit 的 service 块中加入 EnvironmentFile 指向建立的环境变量文件：</p><pre><code>[Unit]
Description=demo
After=network.target nss-lookup.target

[Service]
User=root
EnvironmentFile=/etc/env_addon
ExecStart=/usr/bin/python /path/main.py
Restart=on-failure

[Install]
WantedBy=multi-user.target</code></pre><p>重新加载并重启服务：</p><pre><code>sudo systemctl daemon-reload
sudo systemctl restart demo.service</code></pre><p>如果需要系统的 <strong>~/.bashrc</strong> 同时加载这个自定义的环境变量文件，可以在 bashrc 中加入下面内容：</p><pre><code>set -a; source /etc/env_addon; set +a</code></pre><p>重新加载环境：</p><pre><code>source ~/.bashrc</code></pre><p><strong>参考链接</strong>：<br><a href="https://stackoverflow.com/questions/49764993/using-a-users-bashrc-in-a-systemd-service">Using a user's .bashrc in a systemd service</a><br><a href="https://www.flatcar.org/docs/latest/setup/systemd/environment-variables/">Using environment variables in systemd units Environment directive</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2621.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[修改虚拟交换机 MTU 提高 esxi 虚拟机网络速度]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2613.html" />
<id>https://blog.niekun.net/archives/2613.html</id>
<updated>2022-04-10T12:59:50+08:00</updated>
<published>2022-04-10T12:59:50+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[最近发现我的局域网内网下的网速很慢，只有500M左右，达不到 1000M 的速度。我是通过 ipert3 进行测速的。家里的网络是通过 esxi 下安装的 openwrt，ubuntu 等虚拟机...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2613.html" xml:lang="zh-CN"><![CDATA[
<p>最近发现我的局域网内网下的网速很慢，只有500M左右，达不到 1000M 的速度。我是通过 ipert3 进行测速的。</p><p>家里的网络是通过 esxi 下安装的 openwrt，ubuntu 等虚拟机控制的，通过 esxi 管理页面可以看到接口都运行在 1000M 全双工模式下，说明网线链接是没有问题的：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/3148137121.jpg" alt="1.jpg" title="1.jpg"></p><p>经过查询发现可以通过修改虚拟交换机的 mtu 值到 9000 来提高网络吞吐量从而加快网速。</p><!--more--><h3>修改 mtu</h3><p>进入虚拟交换机栏：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/2344625687.jpg" alt="2.jpg" title="2.jpg"></p><p>点击每一个交换机进入设置界面，点击上面的 edit：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/663844784.jpg" alt="3.jpg" title="3.jpg"></p><p>将 mtu 设置为 9000，并保存配置：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/1003869571.jpg" alt="4.jpg" title="4.jpg"></p><p>虚拟交换机里修改完后，进入 vmkernel NICs 栏：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/520155881.jpg" alt="5.jpg" title="5.jpg"></p><p>点击 vmk0 进入设置界面，同样的点击 edit 修改其 mtu 为 9000 并保存：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/284326956.jpg" alt="6.jpg" title="6.jpg"></p><p>以上就完成了整个虚拟环境 mtu 值的修改，再次通过 iperf3 测速，速率能达到 800M。</p><h3>iperf3 使用</h3><p>下面简单介绍使用 iperf3 测试内网传输速率。</p><p>首先在接收端以下指令运行在服务模式：</p><pre><code>iperf3 -s</code></pre><p>然后再发送端执行以下指令启动测速：</p><pre><code>iperf3 -c xxx.xxx.xxx.xxx -t 30</code></pre><p>以上指令中将地址替换为接收端 IP 地址，<code>-t</code> 参数可以设置测速时间，单位为秒。</p><h3>参考链接</h3><p><a href="https://www.v2ex.com/t/696368">关于 ESXi 虚拟机间拷贝速度慢的问题</a><br><a href="https://www.slashroot.in/iperf-how-test-network-speedperformancebandwidth">IPERF: How to test network Speed,Performance,Bandwidth</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2613.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
<entry>
<title type="html"><![CDATA[esxi 配置自定义 ssl 证书]]></title>
<link rel="alternate" type="text/html" href="https://blog.niekun.net/archives/2611.html" />
<id>https://blog.niekun.net/archives/2611.html</id>
<updated>2022-04-10T12:39:50+08:00</updated>
<published>2022-04-10T12:39:50+08:00</published>
<author>
    <name>admin</name>
    <uri>https://niekun.net</uri>
</author>
<summary type="html"><![CDATA[我家里的主机使用 esxi 管理多个 vm 虚拟机，之前的文章介绍过 esxi 的安装及使用：ESXi 的安装与使用，需要安装的可以参考。通过浏览器访问  vcenter 管理界面默认会强制 h...]]></summary>
<content type="html" xml:base="https://blog.niekun.net/archives/2611.html" xml:lang="zh-CN"><![CDATA[
<p>我家里的主机使用 esxi 管理多个 vm 虚拟机，之前的文章介绍过 esxi 的安装及使用：<a href="https://blog.niekun.net/archives/2213.html">ESXi 的安装与使用</a>，需要安装的可以参考。</p><p>通过浏览器访问  vcenter 管理界面默认会强制 https 模式，但是访问端并没有安装 vcenter 管理网页的证书，所以会提示不安全的链接，下面介绍如何在 esxi 上安装自定义域名的 ssl 证书，并在客户机上安装。</p><!--more--><h3>开启 ssh</h3><p>esxi 上的操作是通过 ssh 的方式，所以首先需要打开 esxi 的 ssh 访问权限。</p><p>访问 esxi 管理界面，在 host 菜单栏，选择 action - sevices - enable ssh：<br><img src="https://blog.niekun.net/usr/uploads/2022/04/1033022978.jpg" alt="1.jpg" title="1.jpg"></p><p><strong>打开 ssh 只对本次开机有效，重启 esxi 后会再次默认关闭。</strong></p><p>然后就可以通过 ssh 访问 esxi。</p><h3>创建证书</h3><p>首先备份当前证书文件，防止修改错误无法恢复，进入 <code>/etc/vmware/ssl</code> 目录，新建 bak 文件夹，将目录内的 rui.crt, rui.csr, rui.key 文件移动到 bak 文件夹内：</p><pre><code>cd /etc/vmware/ssl
mkdir bak
mv rui.* bak/</code></pre><p>然后在 <code>/etc/vmware/ssl</code> 下新建文件 <code>webclient.cnf</code> 编辑文件内容如下：</p><pre><code>[ req ]

default_bits = 2048

default_keyfile = rui.key

distinguished_name = req_distinguished_name

encrypt_key = no

prompt = no

string_mask = nombstr

req_extensions = v3_req

[ v3_req ]

basicConstraints = CA:FALSE

keyUsage = digitalSignature, keyEncipherment, dataEncipherment

extendedKeyUsage = serverAuth, clientAuth

subjectAltName = DNS:&lt;esxi.domain.name&gt;, DNS:&lt;esxi&gt;, IP:&lt;xxx.xxx.xxx.xxx&gt; 

[ req_distinguished_name ]

countryName = US

stateOrProvinceName = VA

localityName = SomeCity

0.organizationName = WOW

organizationalUnitName = Software

commonName = &lt;esxi.domain.name&gt;

[ alt_names ]

DNS.1 = &lt;esxi.domain.name&gt;

DNS.2 = &lt;esxi&gt;

IP.1 = &lt;xxx.xxx.xxx.xxx&gt;</code></pre><p>注意，将以上内容中尖括号<code>&lt;&gt;</code>中的内容替换为你实际的域名和IP地址，<strong>不需要保留尖括号</strong>。</p><p>文件修改并保存后，执行下面命令创建证书文件：</p><pre><code># 创建加密 key，它用来保证证书生效及运行
openssl genrsa -out /etc/vmware/ssl/rui.key 2048

# 创建一个证书注册请求文件，会用到上面创建的配置文件信息并保存到 key 中
openssl req -new -nodes -out /etc/vmware/ssl/rui.csr -keyout /etc/vmware/ssl/rui.key -config /etc/vmware/ssl/webclient.cnf

# 生成证书，使用了 x509 标准格式。其中定义了证书 730 天的有效期，也就是2年，可以根据需要自行更改时间
openssl x509 -req -days 730 -in /etc/vmware/ssl/rui.csr -signkey /etc/vmware/ssl/rui.key -out /etc/vmware/ssl/rui.crt -extensions v3_req -extfile /etc/vmware/ssl/webclient.cnf</code></pre><p>以上命令执行完成后，就在目录下生成了 <strong>rui.key, rui.csr, rui.crt</strong> 三个文件。我们只需要将 <strong>rui.crt</strong> 证书文件复制到客户机上安装，可以通过任何方式复制出来，例如 sftp，winscp 等。</p><p><strong>esxi 上需要重启系统后新的证书才能生效。</strong>注意重启后 ssh 功能可能需要重新打开。</p><h3>客户端安装证书</h3><p>在 macOS 上安装证书，双击复制出来的 rui.crt 安装即可。安装后需要设置为信任，进入 keychain access 中，在 system 栏点击 certificates 菜单项就能找到刚刚安装的证书，双击证书进入属性，点击 trust 菜单，将 when using this certificate 设置为 always trust 即可，关闭时会提示输入密码。</p><p>此时我们就可以以 https 访问 esxi web 管理页面并且不会报证书错误了。</p><h3>参考链接</h3><p><a href="https://www.vmwareblog.org/replace-default-esxi-ssl-certificate-self-signed-certificate-101-introduction/">How to Replace Your Default ESXi SSL Certificate With a Self-Signed Certificate</a></p>
]]></content>
<link rel="replies" type="text/html" href="https://blog.niekun.net/archives/2611.html#comments" thr:count="0" />
<link rel="replies" type="application/atom+xml" href="https://blog.niekun.net/feed/atom/category/Linux/" thr:count="0"/>
</entry>
</feed>