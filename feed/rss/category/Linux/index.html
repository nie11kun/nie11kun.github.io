<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
xmlns="http://purl.org/rss/1.0/"
xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel rdf:about="https://blog.niekun.net/feed/rss/category/Linux/">
<title>Marco Nie - Linux</title>
<link>https://blog.niekun.net/category/Linux/</link>
<description></description>
<items>
<rdf:Seq>
<rdf:li resource="https://blog.niekun.net/archives/1763.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1758.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1757.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1754.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1752.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1747.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1666.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1547.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1378.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1376.html"/>
</rdf:Seq>
</items>
</channel>
<item rdf:about="https://blog.niekun.net/archives/1763.html">
<title>Failed to parse PID from file /opt/nginx/logs/nginx.pid 处理</title>
<link>https://blog.niekun.net/archives/1763.html</link>
<dc:date>2020-09-22T16:27:00+08:00</dc:date>
<description>今天在使用 journalctl 查看 nginx 日志时看到在每次启动服务后会出现一条错误信息：$ journalctl -u nginx
...
nginx.service: Failed to parse PID from file /opt/nginx/logs/nginx.pid: Invalid argument
...
查找了下原因，可能是 nginx 在启动时创建 nginx.pid 文件前 systemd 就在请求这个文件，所以出错了。解决办法就是题前手动创建 systemd 需要的文件：mkdir /etc/systemd/system/nginx.service.d
printf &quot;[Service]\nExecStartPost=/bin/sleep 0.1\n&quot; &gt; /etc/systemd/system/nginx.service.d/override.conf
systemctl daemon-reload以上处理就可以解决问题。参考链接：https://bugs.launchpad.net/ubuntu/+source/nginx/+bug/1581864</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1758.html">
<title>从源码编译安装 python</title>
<link>https://blog.niekun.net/archives/1758.html</link>
<dc:date>2020-09-21T16:35:00+08:00</dc:date>
<description>从源码编译程序的好处是可以使用最新版本，下面介绍如何在 Linux 下编译安装 python 和 pip 环境。下载源码包python 官网：https://www.python.org/当前最新版是 3.8.5，在这个页面找到地址：https://www.python.org/downloads/release/python-385/下载 tgz 压缩包到本地并解压：cd /tmp
wget https://www.python.org/ftp/python/3.8.5/Python-3.8.5.tgz
tar xvf Python-3.8.5.tgz环境安装编译需要安装一些依赖：apt install libffi-dev libgdbm-dev libsqlite3-dev libssl-dev zlib1g-dev
编译python 源码使用标准 GNU 编译系统，详细说明参考：https://blog.niekun.net/archives/883.html将 python 安装到 /opt 目录，先创建文件夹：mkdir /opt/python3.8.5
然后配置 configure：cd /tmp/Python-3.8.5

./configure \
--prefix=/opt/python3.8.5 \
--enable-optimizations \没有错误提示的话就开始编译和安装：make
make install
安装完成后测试执行：/opt/python3.8.5/bin/python3 --version
返回版本信息则安装完成。下面将可执行文件加入系统路径，创建软连接：ln -s /opt/python3.8.5/bin/python3 /usr/bin/python
测试运行：python --version
安装 pip源码编译安装的 python 不自带 pip，需要自己安装，可以使用 get-pip.py 脚本来安装。官网：https://pip.pypa.io/en/stable/installing/下载脚本到本地：curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py使用刚才安装的 python 执行脚本：/opt/python3.8.5/bin/python3 get-pip.py
pip 的安装路径是 /opt/python3.8.5/bin/，测试命令：/opt/python3.8.5/bin/pip3 --version
返回版本信息则安装完成。添加软连接到系统路径：ln -s /opt/python3.8.5/bin/pip3 /usr/bin/pip
测试命令：pip --version
参考链接https://docs.rstudio.com/resources/install-python-source/</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1757.html">
<title>awk 命令的用法</title>
<link>https://blog.niekun.net/archives/1757.html</link>
<dc:date>2020-09-18T16:20:00+08:00</dc:date>
<description>awk 是常用的 Linux 文本操作命令和脚本语言。用来按行提取和处理文本内容，也可以执行简单的逻辑处理。比如我们有一个 txt 文件：ab.c 123 e.rt 456
oh.g 324 b.na 756
si.d 156 o.ui 452执行命令：$ awk '{print $1}' test.txt
ab.c
oh.g
si.d可以看到返回结果为每一行的第一个字符串。默认以空格作为分隔符。$1 为每行第一个字符串，$2 为每行第二个字符串，以此类推。$0 为整个文本。可以同时输出多个内容：$ awk '{print $1, $2}' test.txt
ab.c 123
oh.g 324
si.d 156内部集成的参数FS 区域分割符awk 默认使用空格来分割字符串，也可以自己定义分割符：$ awk 'FS = &quot;.&quot; {print $1, $2}' test.txt
ab c 123 e
oh g 324 b
si d 156 o这时候，ab 和 c 123 e 分别是一个整体。还有一种写法使用 -F 表示，要写在引号外部：$ awk -F. '{print $1, $2}' test.txt
NF 每行字符串个数用 $NF 来表示每行最后一个串：$ awk '{print $NF}' test.txt
456
756
452用 NF 来判断每行字符串格个数：只输出有 4 个字符串的所在行的内容$ awk 'NF == 4 {print $1, $2}' test.txt
ab.c 123
oh.g 324
si.d 156NR 当前行号NR 记录当前行的行号：$ awk '{print NR}' test.txt
1
2
3$ awk '{print NR, $0}' test.txt
1 ab.c 123 e.rt 456
2 oh.g 324 b.na 756
3 si.d 156 o.ui 452OFS 定义输出串分割符字符串输出是可以自定义分割符号：$ awk 'OFS=&quot;/&quot; {print $1, $2}' test.txt
ab.c/123
oh.g/324
si.d/156BEGIN 和 END 规则BEGIN 规则是在 awk 读取输入文本前执行的指令，END 规则是在 awk 输出完字符串后执行的指令。$ awk 'BEGIN {print &quot;begin process&quot;} {print $0} END {print &quot;end process&quot;}' test.txt
begin process
ab.c 123 e.rt 456
oh.g 324 b.na 756
si.d 156 o.ui 452
end process判断模块可以使用常用的判断来过滤输出结果：设置第4个字符串数字需要大于等于500：$ awk '$4 &gt;=500 {print $0}' test.txt
oh.g 324 b.na 756设置行内必须包含字符串 ab:$ awk '/ab/ {print $0}' test.txt
ab.c 123 e.rt 456设置行开始必须包含字符串 ab:$ awk '/^ab/ {print $0}' test.txt
ab.c 123 e.rt 456awk script 脚本如果命令很复杂，可以建立一个脚本来单独执行。建立文件：test.awk#!/usr/bin/awk -f

BEGIN {
  # set the input and output field separators
  FS=&quot;:&quot;
  OFS=&quot;:&quot;
  # zero the accounts counter
  accounts=0
}
{
  # set field 2 to nothing
  $2=&quot;&quot;
  # print the entire line
  print $0
  # count another account
  accounts++
}
END {
  # print the results
  print accounts &quot; accounts.\n&quot;
}可执行权限：chmod +x test.awk
执行：./test.awk /etc/passwd
参考链接https://www.howtogeek.com/562941/how-to-use-the-awk-command-on-linux/http://linuxcommand.org/lc3_adv_awk.php</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1754.html">
<title>${1%str} 在 shell 脚本的用法</title>
<link>https://blog.niekun.net/archives/1754.html</link>
<dc:date>2020-09-18T15:25:00+08:00</dc:date>
<description>执行 shell 脚本时经常会有传入参数，如：./test.sh abcdef abc.bbb
以上的命令使用了两个传入参数，abcdef,abc.bbb。在脚本里使用时，$1 就表示第一个参数，$2 就表示第二个参数:var1 = $1
var2 = $2在脚本中有一种用法，如：${1%def}jjj。他的意思就是将 $1 最后的字符 def 替换为 jjj：newstr1 = ${1%def}jjjnewstr1 的值就是 abcjjj。newstr2 = ${2%.bbb}.cccnewstr2 的值就是 abc.ccc。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1752.html">
<title>FFmpeg 简单用法</title>
<link>https://blog.niekun.net/archives/1752.html</link>
<dc:date>2020-09-18T15:03:12+08:00</dc:date>
<description>FFmpeg 是视频处理最常用的开源软件。它功能强大，用途广泛，大量用于视频网站和商业软件（比如 Youtube 和 iTunes），也是许多音频和视频格式的标准编码/解码实现。官方网站：https://www.ffmpeg.org/安装最简单的方法就是用包管理工具如：apt 安装：apt update
apt install ffmpeg
或者也可以从源码安装，可以参考我之前的教程：https://blog.niekun.net/archives/891.html常用指令查看 ffmpeg 版本：ffmpeg -version
查看支持的编码格式：如 h.264, h.265ffmpeg -codecs
查看支持的容器：如 mp4, mp3, mkvffmpeg -formats
查看已安装的编码器：如 libx264, libx265, libvpx, aacffmpeg -encoders
使用格式FFmpeg 的命令行参数非常多，可以分成五个部分。ffmpeg {1} {2} -i {3} {4} {5}
上面命令中，五个部分的参数依次如下：全局参数
输入文件参数
输入文件
输出文件参数
输出文件参数太多的时候，为了便于查看，ffmpeg 命令可以写成多行:$ ffmpeg \
[全局参数] \
[输入文件参数] \
-i [输入文件] \
[输出文件参数] \
[输出文件]下面是一个例子:ffmpeg \
-y \ # 全局参数
-c:a libfdk_aac -c:v libx264 \ # 输入文件参数
-i input.mp4 \ # 输入文件
-c:v libvpx-vp9 -c:a libvorbis \ # 输出文件参数
output.webm # 输出文件上面的命令将 mp4 文件转成 webm 文件，这两个都是容器格式。输入的 mp4 文件的音频编码格式是 aac，视频编码格式是 H.264；输出的 webm 文件的视频编码格式是 VP9，音频格式是 Vorbis。如果不指明编码格式，FFmpeg 会自己判断输入文件的编码。一般可以省略输入文件参数。常用命令参数-c：指定编码器
-c copy：直接复制，不经过重新编码（这样比较快）
-c:v：指定视频编码器
-c:a：指定音频编码器
-i：指定输入文件
-an：去除音频流
-vn： 去除视频流
-preset：指定输出的视频质量，会影响文件的生成速度，有以下几个可用的值 ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow。
-y：不经过确认，输出时直接覆盖同名文件。常规使用方法查看元数据信息，如时长，比特率等：ffmpeg -i test.mp4
输出的信息较多，可以通过 -hide_banner 只显示媒体文件信息：ffmpeg -i test.mp4 -hide_banner
转码，如 avi to h.264:ffmpeg -i test.avi -c:v libx264 test.mp4
转换容器：ffmpeg -i test.mp4 -c copy test.webm转换容器不需要转码，所以直接 copy 即可。转换码率，转换成固定码率：ffmpeg -i test.mp4 -b:v 500k test_out.mp4
转换码率，转换成一个码率范围：ffmpeg -i test.mp4 -minrate 964K -maxrate 3856K -bufsize 2000K test_out.mp4
改变分辨率：转换成 480pffmpeg \
-i input.mp4 \
-vf scale=480:-1 \
output.mp4视频中提取音频：ffmpeg \
-i input.mp4 \
-vn -c:a copy \
output.aac上面例子中，-vn 表示去掉视频，-c:a copy 表示不改变音频编码，直接拷贝。视频截图：下面的例子是从指定时间开始，连续对1秒钟的视频进行截图ffmpeg \
-y \
-i input.mp4 \
-ss 00:01:24 -t 00:00:01 \
output_%3d.jpg%3d 在 shell 里表示至少输出3个字符空间的数字：% means &quot;Print a variable here&quot;
3 means &quot;use at least 3 spaces to display, padding as needed&quot;
d means &quot;The variable will be an integer&quot;如果只需要截一张图，可以指定只截取一帧。$ ffmpeg \
-ss 01:23:45 \
-i input \
-vframes 1 -q:v 2 \
output.jpg上面例子中，-vframes 1 指定只截取一帧，-q:v 2 表示输出的图片质量，一般是1到5之间（1 为质量最高）。裁剪:裁剪（cutting）指的是，截取原始视频里面的一个片段，输出为一个新视频。可以指定开始时间（start）和持续时间（duration），也可以指定结束时间（end）。$ ffmpeg -ss [start] -i [input] -t [duration] -c copy [output]
$ ffmpeg -ss [start] -i [input] -to [end] -c copy [output]下面是实际的例子。# 从1分50秒开始截取10.5秒
ffmpeg -ss 00:01:50 -i test.mp4 -t 10.5 -c copy out.mp4

# 从25秒开始截取10秒
ffmpeg -ss 25 -i test.mp4 -to 10 -c copy out.mp4
ffmpeg -i test.mp4 -ss 25 -to 10 -c copy out.mp4上面例子中，-c copy 表示不改变音频和视频的编码格式，直接拷贝，这样会快很多。高级用法压缩视频内容到指定容量大小使用的技术主要是 ffmpeg 的 2 pass 方法和 ffprobe 得到码率和时长信息。bash脚本：#!/bin/bash

target_video_size_MB=&quot;$2&quot;
origin_duration_s=$(ffprobe -v error -show_streams -select_streams a &quot;$1&quot; | grep -Po &quot;(?&lt;=^duration\=)\d*\.\d*&quot;)
origin_audio_bitrate_kbit_s=$(ffprobe -v error -pretty -show_streams -select_streams a &quot;$1&quot; | grep -Po &quot;(?&lt;=^bit_rate\=)\d*\.\d*&quot;)
target_audio_bitrate_kbit_s=$origin_audio_bitrate_kbit_s # TODO for now, make audio bitrate the same
target_video_bitrate_kbit_s=$(\
    awk \
    -v size=&quot;$target_video_size_MB&quot; \
    -v duration=&quot;$origin_duration_s&quot; \
    -v audio_rate=&quot;$target_audio_bitrate_kbit_s&quot; \
    'BEGIN { print  ( ( size * 8192.0 ) / ( 1.048576 * duration ) - audio_rate ) }')

ffmpeg \
    -y \
    -i &quot;$1&quot; \
    -c:v libx264 \
    -b:v &quot;$target_video_bitrate_kbit_s&quot;k \
    -pass 1 \
    -an \
    -f mp4 \
    /dev/null \
&amp;&amp; \
ffmpeg \
    -i &quot;$1&quot; \
    -c:v libx264 \
    -b:v &quot;$target_video_bitrate_kbit_s&quot;k \
    -pass 2 \
    -c:a aac \
    -b:a &quot;$target_audio_bitrate_kbit_s&quot;k \
    &quot;${1%.*}-$2mB.mp4&quot;使用方法：压缩视频到 50 MB 大小./script.sh test.mp4 50
切割视频到指定时长的多个视频使用的技术主要是 python，ffprobe 得到视频时长，然后计算需要切割为几个视频。python 脚本：#!/usr/bin/env python

import csv
import subprocess
import math
import json
import os
import shlex
from optparse import OptionParser


def split_by_manifest(filename, manifest, vcodec=&quot;copy&quot;, acodec=&quot;copy&quot;,
                      extra=&quot;&quot;, **kwargs):

    if not os.path.exists(manifest):
        print(&quot;File does not exist: %s&quot; % manifest)
        raise SystemExit

    with open(manifest) as manifest_file:
        manifest_type = manifest.split(&quot;.&quot;)[-1]
        if manifest_type == &quot;json&quot;:
            config = json.load(manifest_file)
        elif manifest_type == &quot;csv&quot;:
            config = csv.DictReader(manifest_file)
        else:
            print(&quot;Format not supported. File must be a csv or json file&quot;)
            raise SystemExit

        split_cmd = [&quot;ffmpeg&quot;, &quot;-i&quot;, filename, &quot;-vcodec&quot;, vcodec,
                     &quot;-acodec&quot;, acodec, &quot;-y&quot;] + shlex.split(extra)
        try:
            fileext = filename.split(&quot;.&quot;)[-1]
        except IndexError as e:
            raise IndexError(&quot;No . in filename. Error: &quot; + str(e))
        for video_config in config:
            split_str = &quot;&quot;
            split_args = []
            try:
                split_start = video_config[&quot;start_time&quot;]
                split_length = video_config.get(&quot;end_time&quot;, None)
                if not split_length:
                    split_length = video_config[&quot;length&quot;]
                filebase = video_config[&quot;rename_to&quot;]
                if fileext in filebase:
                    filebase = &quot;.&quot;.join(filebase.split(&quot;.&quot;)[:-1])

                split_args += [&quot;-ss&quot;, str(split_start), &quot;-t&quot;,
                               str(split_length), filebase + &quot;.&quot; + fileext]
                print(&quot;########################################################&quot;)
                print(&quot;About to run: &quot;+&quot; &quot;.join(split_cmd+split_args))
                print(&quot;########################################################&quot;)
                subprocess.check_output(split_cmd+split_args)
            except KeyError as e:
                print(&quot;############# Incorrect format ##############&quot;)
                if manifest_type == &quot;json&quot;:
                    print(&quot;The format of each json array should be:&quot;)
                    print(&quot;{start_time: &lt;int&gt;, length: &lt;int&gt;, rename_to: &lt;string&gt;}&quot;)
                elif manifest_type == &quot;csv&quot;:
                    print(&quot;start_time,length,rename_to should be the first line &quot;)
                    print(&quot;in the csv file.&quot;)
                print(&quot;#############################################&quot;)
                print(e)
                raise SystemExit


def get_video_length(filename):

    output = subprocess.check_output((&quot;ffprobe&quot;, &quot;-v&quot;, &quot;error&quot;, &quot;-show_entries&quot;,
                                      &quot;format=duration&quot;, &quot;-of&quot;, &quot;default=noprint_wrappers=1:nokey=1&quot;, filename)).strip()
    video_length = int(float(output))
    print(&quot;Video length in seconds: &quot;+str(video_length))

    return video_length


def ceildiv(a, b):
    return int(math.ceil(a / float(b)))


def split_by_seconds(filename, split_length, vcodec=&quot;copy&quot;, acodec=&quot;copy&quot;,
                     extra=&quot;&quot;, video_length=None, **kwargs):
    if split_length and split_length &lt;= 0:
        print(&quot;Split length can't be 0&quot;)
        raise SystemExit

    if not video_length:
        video_length = get_video_length(filename)
    split_count = ceildiv(video_length, split_length)
    if(split_count == 1):
        print(&quot;Video length is less then the target split length.&quot;)
        raise SystemExit

    split_cmd = [&quot;ffmpeg&quot;, &quot;-i&quot;, filename, &quot;-vcodec&quot;,
                 vcodec, &quot;-acodec&quot;, acodec] + shlex.split(extra)
    try:
        filebase = &quot;.&quot;.join(filename.split(&quot;.&quot;)[:-1])
        fileext = filename.split(&quot;.&quot;)[-1]
    except IndexError as e:
        raise IndexError(&quot;No . in filename. Error: &quot; + str(e))
    for n in range(0, split_count):
        split_args = []
        if n == 0:
            split_start = 0
        else:
            split_start = split_length * n

        split_args += [&quot;-ss&quot;, str(split_start), &quot;-t&quot;, str(split_length),
                       filebase + &quot;-&quot; + str(n+1) + &quot;-of-&quot; +
                       str(split_count) + &quot;.&quot; + fileext]
        print(&quot;About to run: &quot;+&quot; &quot;.join(split_cmd+split_args))
        subprocess.check_output(split_cmd+split_args)


def main():
    parser = OptionParser()

    parser.add_option(&quot;-f&quot;, &quot;--file&quot;,
                      dest=&quot;filename&quot;,
                      help=&quot;File to split, for example sample.avi&quot;,
                      type=&quot;string&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-s&quot;, &quot;--split-size&quot;,
                      dest=&quot;split_length&quot;,
                      help=&quot;Split or chunk size in seconds, for example 10&quot;,
                      type=&quot;int&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-c&quot;, &quot;--split-chunks&quot;,
                      dest=&quot;split_chunks&quot;,
                      help=&quot;Number of chunks to split to&quot;,
                      type=&quot;int&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-S&quot;, &quot;--split-filesize&quot;,
                      dest=&quot;split_filesize&quot;,
                      help=&quot;Split or chunk size in bytes (approximate)&quot;,
                      type=&quot;int&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;--filesize-factor&quot;,
                      dest=&quot;filesize_factor&quot;,
                      help=&quot;with --split-filesize, use this factor in time to&quot;
                      &quot; size heuristics [default: %default]&quot;,
                      type=&quot;float&quot;,
                      action=&quot;store&quot;,
                      default=0.95
                      )
    parser.add_option(&quot;--chunk-strategy&quot;,
                      dest=&quot;chunk_strategy&quot;,
                      help=&quot;with --split-filesize, allocate chunks according to&quot;
                      &quot; given strategy (eager or even)&quot;,
                      type=&quot;choice&quot;,
                      action=&quot;store&quot;,
                      choices=['eager', 'even'],
                      default='eager'
                      )
    parser.add_option(&quot;-m&quot;, &quot;--manifest&quot;,
                      dest=&quot;manifest&quot;,
                      help=&quot;Split video based on a json manifest file. &quot;,
                      type=&quot;string&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-v&quot;, &quot;--vcodec&quot;,
                      dest=&quot;vcodec&quot;,
                      help=&quot;Video codec to use. &quot;,
                      type=&quot;string&quot;,
                      default=&quot;copy&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-a&quot;, &quot;--acodec&quot;,
                      dest=&quot;acodec&quot;,
                      help=&quot;Audio codec to use. &quot;,
                      type=&quot;string&quot;,
                      default=&quot;copy&quot;,
                      action=&quot;store&quot;
                      )
    parser.add_option(&quot;-e&quot;, &quot;--extra&quot;,
                      dest=&quot;extra&quot;,
                      help=&quot;Extra options for ffmpeg, e.g. '-e -threads 8'. &quot;,
                      type=&quot;string&quot;,
                      default=&quot;&quot;,
                      action=&quot;store&quot;
                      )
    (options, args) = parser.parse_args()

    def bailout():
        parser.print_help()
        raise SystemExit

    if not options.filename:
        bailout()

    if options.manifest:
        split_by_manifest(**(options.__dict__))
    else:
        video_length = None
        if not options.split_length:
            video_length = get_video_length(options.filename)
            file_size = os.stat(options.filename).st_size
            split_filesize = None
            if options.split_filesize:
                split_filesize = int(
                    options.split_filesize * options.filesize_factor)
            if split_filesize and options.chunk_strategy == 'even':
                options.split_chunks = ceildiv(file_size, split_filesize)
            if options.split_chunks:
                options.split_length = ceildiv(
                    video_length, options.split_chunks)
            if not options.split_length and split_filesize:
                options.split_length = int(
                    split_filesize / float(file_size) * video_length)
        if not options.split_length:
            bailout()
        split_by_seconds(video_length=video_length, **(options.__dict__))


if __name__ == '__main__':
    main()使用方法：将视频切割为单个视频100秒./split.py -f test.mp4 -s 100
ffprobe 使用ffprobe 可以用来得到视频信息。视频时长：秒ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 input.mp4
视频码率：bitffprobe -v error -show_entries format=bit_rate -of default=noprint_wrappers=1:nokey=1 input.mp4
参考链接http://www.ruanyifeng.com/blog/2020/01/ffmpeg.htmlhttps://stackoverflow.com/questions/29082422/ffmpeg-video-compression-specific-file-sizehttps://github.com/c0decracker/video-splitterhttps://trac.ffmpeg.org/wiki/FFprobeTips</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1747.html">
<title>Linux 系统时间设置问题</title>
<link>https://blog.niekun.net/archives/1747.html</link>
<dc:date>2020-09-17T10:47:00+08:00</dc:date>
<description>昨天重装了 vps 系统，在设置 crontab 定时任务时发现并没有在指定的时间执行脚本。于是就进行排查问题。测试在 /etc/crontab 添加一条测试任务:30  10    *  *  * root python -V &gt; /root/test.log
在 10：30 并没有看到 test.log 文件生成。通过 systemctl status cron 查看信息：Sep 17 10:21:01 niekun-bandwagon CRON[946]: pam_unix(cron:session): session clos
Sep 17 10:29:01 niekun-bandwagon cron[451]: (*system*) RELOAD (/etc/crontab)在 10：29 crontab 脚本已经重新加载过了，但是并没有执行任务。通过命令 cat /var/log/syslog | grep cron 查看系统日志：Sep 16 21:46:35 niekun-bandwagon cron[451]: (CRON) INFO (pidfile fd = 3)
Sep 16 21:46:35 niekun-bandwagon cron[451]: (CRON) INFO (Running @reboot jobs)
Sep 16 22:29:01 niekun-bandwagon cron[451]: (*system*) RELOAD (/etc/crontab)发现日志的时间比我当前时间晚了 12 个小时，会不会就是系统日期问题导致脚本没有达到设定的时间？在按装新系统的后，使用 date 命令查看当前系统时间，发现时间是 UTC 时间，我通过 tzselect 命令设置了时区：[root@db-server ~]# tzselect 
Please identify a location so that time zone rules can be set correctly.
Please select a continent or ocean.
 1) Africa
 2) Americas
 3) Antarctica
 4) Arctic Ocean
 5) Asia
 6) Atlantic Ocean
 7) Australia
 8) Europe
 9) Indian Ocean
10) Pacific Ocean
11) none - I want to specify the time zone using the Posix TZ format.
#? 5
Please select a country.
 1) Afghanistan           18) Israel                35) Palestine
 2) Armenia               19) Japan                 36) Philippines
 3) Azerbaijan            20) Jordan                37) Qatar
 4) Bahrain               21) Kazakhstan            38) Russia
 5) Bangladesh            22) Korea (North)         39) Saudi Arabia
 6) Bhutan                23) Korea (South)         40) Singapore
 7) Brunei                24) Kuwait                41) Sri Lanka
 8) Cambodia              25) Kyrgyzstan            42) Syria
 9) China                 26) Laos                  43) Taiwan
10) Cyprus                27) Lebanon               44) Tajikistan
11) East Timor            28) Macau                 45) Thailand
12) Georgia               29) Malaysia              46) Turkmenistan
13) Hong Kong             30) Mongolia              47) United Arab Emirates
14) India                 31) Myanmar (Burma)       48) Uzbekistan
15) Indonesia             32) Nepal                 49) Vietnam
16) Iran                  33) Oman                  50) Yemen
17) Iraq                  34) Pakistan
#? 9
Please select one of the following time zone regions.
1) east China - Beijing, Guangdong, Shanghai, etc.
2) Heilongjiang (except Mohe), Jilin
3) central China - Sichuan, Yunnan, Guangxi, Shaanxi, Guizhou, etc.
4) most of Tibet &amp; Xinjiang
5) west Tibet &amp; Xinjiang
#? 1
 
The following information has been given:
 
        China
        east China - Beijing, Guangdong, Shanghai, etc.
 
Therefore TZ='Asia/Shanghai' will be used.
Local time is now:      Sun Jan 11 23:31:51 CST 2015.
Universal Time is now:  Sun Jan 11 15:31:51 UTC 2015.
Is the above information OK?
1) Yes
2) No
#? yes
Please enter 1 for Yes, or 2 for No.
#? 1
 
You can make this change permanent for yourself by appending the line
        TZ='Asia/Shanghai'; export TZ
to the file '.profile' in your home directory; then log out and log in again.
 
Here is that TZ value again, this time on standard output so that you
can use the /usr/bin/tzselect command in shell scripts:
Asia/Shanghai将 TZ='Asia/Shanghai'; export TZ 写入 ~/.profile，并刷新文件：source .bash_profile测试当前系统时间：root@niekun-bandwagon:~# date
Thu Sep 17 10:44:00 CST 2020
但是系统日志记录的时间还是不对，这就可能还是时区不对，手动复制亚洲时区文件到目录：cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
更新 rsyslog 进程：systemctl restart rsyslog
再次测试发现系统日志时间对了，crontab 脚本也可以正确执行。也可以使用 timedatectl 命令设置时区：# 查看当前时区设置
$ timedatectl

# 显示所有可用的时区
$ timedatectl list-timezones                                                                                   

# 设置当前时区
$ sudo timedatectl set-timezone Asia/Shanghai</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1666.html">
<title>Linux 下使用 OptiPNG 压缩图片</title>
<link>https://blog.niekun.net/archives/1666.html</link>
<dc:date>2020-07-14T17:25:00+08:00</dc:date>
<description>最近越来也发现自己的博客加载图片变慢了，由于我很多教程是教 PS 的，会使用到很多图片和截图，所以影响尤其明显。每张图片小则 400Kb 大则 2-3Mb，对于网络浏览不太友好。可以直接在服务器上进行图片压缩，用到的工具是 OptiPNG。OptiPNG home page：http://optipng.sourceforge.net/编译安装我选择从源码编译安装，这样可以直接使用最新版本。如何从源码编译程序可以参考我的文章：https://blog.niekun.net/archives/883.html首先从官网下载源码到 vps 并解压：cd /tmp
wget http://prdownloads.sourceforge.net/optipng/optipng-0.7.7.tar.gz
tar xvf optipng-0.7.7.tar.gz
新建安装路径：mkdir /opt/optipng-0.7.7
ln -s /opt/optipng-0.7.7 /opt/optipng
configure & make：cd /tmp/optipng-0.7.7
./configure --prefix=/opt/optipng-0.7.7
make
make install
测试是否可以执行：/opt/optipng/bin/optipng
创建系统链接：ln -s /opt/optipng/bin/optipng /usr/local/bin/optipng
使用可以使用命令查看处理前处理后的图片体积：ls -lh a.png
压缩一张 png 图片：optipng a.png
压缩目录下的所有 png 图片：optipng *.png
可以自定义压缩等级：Optimization levels:
    -o0         &lt;=&gt;     -o1 -nx -nz                             (0 or 1 trials)
    -o1         &lt;=&gt;     -zc9 -zm8 -zs0 -f0                      (1 trial)
                (or...) -zc9 -zm8 -zs1 -f5                      (1 trial)
    -o2         &lt;=&gt;     -zc9 -zm8 -zs0-3 -f0,5                  (8 trials)
    -o3         &lt;=&gt;     -zc9 -zm8-9 -zs0-3 -f0,5                (16 trials)
    -o4         &lt;=&gt;     -zc9 -zm8 -zs0-3 -f0-5                  (24 trials)
    -o5         &lt;=&gt;     -zc9 -zm8-9 -zs0-3 -f0-5                (48 trials)
    -o6         &lt;=&gt;     -zc1-9 -zm8 -zs0-3 -f0-5                (120 trials)
    -o7         &lt;=&gt;     -zc1-9 -zm8-9 -zs0-3 -f0-5              (240 trials)
    -o7 -zm1-9  &lt;=&gt;     -zc1-9 -zm1-9 -zs0-3 -f0-5              (1080 trials)
Notes:
    The combination for -o1 is chosen heuristically.
    Exhaustive combinations such as &quot;-o7 -zm1-9&quot; are not generally recommended.
Examples:
    optipng file.png                                            (default speed)
    optipng -o5 file.png                                        (slow)
    optipng -o7 file.png                                        (very slow)</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1547.html">
<title>使用 SCP 管理远程服务器文件</title>
<link>https://blog.niekun.net/archives/1547.html</link>
<dc:date>2020-04-03T08:55:39+08:00</dc:date>
<description>安全复制（英语：Secure copy，缩写SCP）是指在本地主机与远程主机或者两台远程主机之间基于Secure Shell（SSH）协议安全地传输电脑文件。SCP是一种基于BSD RCP协议的网络传输协议，[3] 支持同一个网络上主机之间传输文件。SCP使用Secure Shell（SSH）完成数据传输，并使用同时用它进行身份认证，从而确保数据传输时的真实性和保密性。客户端可以向服务器发送（上传）文件，可选包含其基本属性（权限、时间戳）。客户端也可以请求（下载）一个服务器的文件或目录。SCP默认通过TCP端口22运行。和 SCP 类似功能的是 SFTP 协议，也是使用 SSH 传输数据，具体使用方法参考：https://blog.niekun.net/archives/130.htmlLinux 系统可以直接使用 scp 命令进行操作，Windows 系统可以安装 WinSCP，进行操作。下面介绍 Linux 下使用 scp 进行文件传输。复制远程文件到本地:scp -P port username@from_host:file.txt /local/directory/
复制本地文件到远程:scp file.txt username@to_host:/remote/directory/
复制远程文件夹到本地:scp -r username@from_host:/remote/directory/  /local/directory/

复制本地文件夹到远程:scp -r /local/directory/ username@to_host:/remote/directory/
复制远程文件到另一个远程服务器:scp username@from_host:/remote/directory/file.txt username@to_host:/remote/directory/
执行上面的命令后会提示要求输入所登录的远程用户密码。如果远程服务器 ssh 端口不是默认的 22，需要使用 -P 参数进行设置，注意是大写 P。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1378.html">
<title>NGINX Reverse Proxy 反向代理的使用</title>
<link>https://blog.niekun.net/archives/1378.html</link>
<dc:date>2020-03-30T11:05:00+08:00</dc:date>
<description>Proxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.nginx 可以将一个客户端的请求反向代理到其他地址/端口，从客户端上看不到代理过程。方向代理的常用来处理服务器上部署的多个网络服务，根据请求呈现不同网页内容，转发请求到其他应用程序等。支持转发的协议有：  HTTP，FastCGI, uwsgi, SCGI, and memcached。不同于 nginx 的重定向 return/rewrite/try_fiels 功能，反向代理对于客户端是不可见的，关于重定向的语法参考：https://blog.niekun.net/archives/195.html下面介绍 ngx_http_proxy_module 模块的使用方式。语法proxy_pass 指令将请求转发到其他代理服务器。转发一个 http 请求到另一个地址：location /some/path/ {
    proxy_pass http://www.example.com/link/;
}以上示例将访问 location 段的请求转发到特定地址，这里有几个规则需要注意：1.代理地址如果不写明 location 段，则转发请求 location 到新的地址：location /some/path/ {
    proxy_pass http://www.example.com;
}以上规则下，访问 /some/path/.test.html 时，会转发到 http://www.example.com/some/path/.test.htmllocation ~ \.php {
    proxy_pass http://127.0.0.1:8000;
}以上规则下，访问 /some/path/test.php 时，会转发到 127.0.0.1:8000/some/path/test.php2.代理地址包含新的 location 时会替换掉请求 location 部分：location /some/path/ {
    proxy_pass http://www.example.com/new/;
}以上规则下，访问 /some/path/test.html 时，会转发到 http://www.example.com/new/test.html，注意 http://www.example.com/ 和 http://www.example.com 不同，也属于包含根路径 location 段的。proxy_pass 语法用来转发给 http 服务，还支持转发给其他协议的服务：fastcgi_pass 转发给 FastCGI server 如 php 服务uwsgi_pass 转发给 uwsgi server 如 python 服务scgi_pass 转发给 SCGI servermemcached_pass 转发给 memcached server转发的服务地址可以用一个 upstream 组来实现负载均衡：http {
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
    
    server {
        ...
        location / {
            proxy_pass http://backend;
        }
    }
}以上是一个简单的负载均衡代理转发示例。关于 upstream 详细使用参考官方教程proxy_redirect 响应头 location/refresh 重定向当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location/Refresh 字段。语法结构：proxy_redirect default;
proxy_redirect off;
proxy_redirect redirect replacement;
默认设置是：proxy_redirect default。http 响应头的 location 段 HTTP Location 是在两种情况使用在响应头中：要求网页浏览器加载其他网页(域名转址)。在这种情况下，应该使用HTTP状态码3xx发送Location头。提供有关新创建资源位置的信息。在这种情况下，应该使用HTTP状态码201或202发送Location头。通过修改 location 可以让客户端接收到响应后，访问重定向到新的 location。更详细的关于重定向/刷新请求头概念，需要理解 http 协议的结构，查看我的教程：HTTP 协议结构如果设置：server {listen 8080;
servername frontend;

proxy_redirect http://localhost:8000/two/ http://frontend:8080/one/;
...}代理服务器返回的 http 头信息：HTTP/1.1 302 Found
Location: http://localhost:8000/two/some/uri/
则返回给客户端的 Location 段被重写为: http://frontend:8080/one/some/uri/，客户端接收到后就会去重新访问这个新的地址。server 名也可以被省略：proxy_redirect http://localhost:8000/two/ /
以上指令返回给客户端的 Location 段被重写为: http://frontend:8080/some/uri/proxy_redirect 默认设置值为：default，它会自动根据 server location 段和 proxy_pass 地址来修改头信息，以下两种写法效果一样：location /one/ {
    proxy_pass     http://localhost:8000/two/;
    proxy_redirect default;

location /one/ {
    proxy_pass     http://localhost:8000/two/;
    proxy_redirect http://localhost:8000/two/ /one/;以上两种写法都是将返回 location 头信息中 http://localhost:8000/two/ 修改为 http://frontend:8080/one/redirect 和 replacement 都可以包含参数：proxy_redirect http://$proxy_host:8000/ $scheme$host:$server_port/;
rederect 可以使用正则匹配：proxy_redirect ~^(http://[^:]+):\d+(/.+)$ $1$2;
proxy_redirect ~*/user/([^/]+)/(.+)$      http://$1.example.com/$2;
可以同时写多个 proxy_redirect 指令来处理不同的重定向地址。使用 proxy_redirect off 具有最高优先级，会取消当前同一级的所有 proxy_redirect 指令。一个完整例子：server {
    listen           8080;
    server_name      127.0.0.1;

    location /return {
        return 301 https://niekun.net;
    }
    location /proxy {
        proxy_pass  $scheme://$http_host/return;
        proxy_redirect https://niekun.net /echo;
    }
    location /echo {
        default_type text/plain;
        echo 'remote address: $remote_addr';
    }
}代理过程：客户端访问：http://127.0.0.1:8080/proxynginx 转发到：http://127.0.0.1:8080/return代理服务器响应 301 重定向到：https://niekun.net，http 头的 location 值为：https://niekun.netnginx 将 http 头的 location 修改为：http://127.0.0.1:8080/echonginx 将修改后的响应内容发送给客户端客户端根据响应再次访问：http://127.0.0.1:8080/echo转发请求头信息默认情况下，nginx 反向代理时会舍弃原始请求头中的空字符串项，并重新设定两个请求头内容：Host 和 Connection：Host -&gt; $proxy_host  也就是 proxy_pass 里的 hostConnection -&gt; close关于 http 请求头 header 的可定义的项目参考我的教程：HTTP 协议结构想要设置或修改传递给代理服务的请求头，使用 proxy_set_header 指令：location /some/path/ {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Accept-Encoding &quot;&quot;;
    proxy_pass http://localhost:8000;
}以上示例的处理结果是：设置 Host 为本 server 的host 地址而不是转发地址设置 X-Real-IP 为客户端 IP 地址，用来识别访问服务的客户信息清空 Accept-Encoding 的内容mapping headers 动态请求头内容proxy_set_header 支持使用内部变量来定义，也可以使用 map 指令配合自定义参数来根据请求清空动态设置相关 header 内容，注意 map 指令要写在 http 段：map $http_cloudfront_forwarded_proto $cloudfront_proto {
    default &quot;http&quot;;
    https &quot;https&quot;;
}
server {
    ...
    location / {
        proxy_set_header X-Forwarded-Proto $cloudfront_proto;
        proxy_pass http://app;
        proxy_redirect off;
        ...
    }
}以上示例中 $http_cloudfront_forwarded_proto 是已知变量，$cloudfront_proto 是我自定义的变量，使用 map 指令来根据前者的值设置后者的值，然后在 proxy_set_header 设置。map 指令支持以两个因变量来给终变量赋值,语法示例如下：map &quot;$http_cloudfront_forwarded_proto:$http_x_forwarded_proto&quot; $cloudfront_proto {
    default &quot;http&quot;;
    &quot;:https&quot; &quot;https&quot;;
    &quot;https:&quot; &quot;https&quot;;
    &quot;https:http&quot; &quot;https&quot;;
    &quot;http:https&quot; &quot;https&quot;;
    &quot;https:https&quot; &quot;https&quot;;
}如果用户访问时加了代理或者网站有 CDN，$remote_addr 的值就不是用户真实 IP 了。客户端也可以伪造 X-Forwarded-For 信息，使用 map 指令提取用户真实 IP，注意 map 指令要写在配置文件的 http 段：map $http_x_forwarded_for  $client_real_ip {
    default                         $remote_addr;
    ~^(([0-9\.]+),\s?)*([0-9\.]+)$  $3;
}

server {
    echo 'remote address: $client_real_ip';
}如果 $http_x_forwarded_for 没有匹配到则赋值为 $remote_addr，如果匹配到了则提取最后一个 IP。$client_real_ip 变量就是真是客户端的 IP 地址。关于 $http_x_forwarded_for 和 $proxy_add_x_forwarded_for 参考我的文章：获取用户真实 IP in Nginxbuffers 缓存区默认情况下 nginx 缓存来自 proxy server 的响应内容。nginx 会一直在内部缓存来自代理服务器的响应内容直到内容接收完成，然后才发送给客户端。缓存能够帮助减轻客户端的压力，但会浪费服务器的资源和响应。但是打开缓存功能的另一个好处是当客户端再次进行一个缓存过的请求时，nginx 可以快速的返回已经在缓存区的内容。使用 proxy_buffering 指令控制缓存打开/关闭。默认是 on 状态。proxy_buffers 指令控制缓存区数量和缓存大小。第一个来自代理服务器的响应会缓存到单独的区域，proxy_buffer_size 指令控制这一区域的大小：location /some/path/ {
    proxy_buffers 16 4k;
    proxy_buffer_size 2k;
    proxy_pass http://localhost:8000;
}以上示例会给 来自代理服务器：http://localhost:8000 的响应建立 16 个缓存区，每个区域 4kb 空间，第一个响应缓存区 2kb 空间。如果关闭缓存，来自代理服务器的响应会即时发送给客户端，对于想要快速响应的使用场景可以关闭缓存：location /some/path/ {
    proxy_buffering off;
    proxy_pass http://localhost:8000;
}设置出口 IP 地址默认情况下 nginx 向 proxy 上游发起请求连接，代理服务器看到的请求 IP 地址来自 nignx 服务器地址。有时候 web 服务器会设置只允许特定 IP 地址的访问，可以通过 proxy_bind 指令来修改，nginx 用户必须是 root 才行：user root;
...
http{
    ...
    server {
        location /app1/ {
            proxy_bind proxy_bind $remote_addr transparent;
            proxy_pass http://example.com/app1/;
        }
    }
}以上示例中，代理服务器看到的请求来源就会是真正的访问客户端 IP 地址,也就是实现了透明代理。nginx 配置后还需要配置 iptables 路由表来处理代理服务器响应内容：新建一个链，把过来的tcp包都打上标记。新建一个路由表100，让有标记的包都走表100。在路由表100加入一个默认路由，把所有包都扔到lo网卡上去。      #### 新建一个 DIVERT 给包打标签
     sudo iptables -t mangle -N DIVERT;
     sudo iptables -t mangle -A DIVERT -j MARK --set-mark 1;
     sudo iptables -t mangle -A DIVERT -j ACCEPT;

     #### 把tcp的包给DIVERT处理
     sudo iptables -t mangle -A PREROUTING -p tcp -m socket -j DIVERT;

     #### 有标签的包去查名为 100 的路由表
     sudo ip rule add fwmark 1 lookup 100

     #### 100的路由表里就一条默认路由，把所有包都扔到lo网卡上去
     sudo ip route add local 0.0.0.0/0 dev lo table 100;具体实现我还不太懂，后期再研究下。以上就是 http 代理服务器基本使用，下面简单介绍其他集中代理服务器的语法。fastcgi 代理服务器Nginx must rely on a separate PHP processor to handle PHP requests. Most often, this processing is handled with php-fpm, a PHP processor that has been extensively tested to work with Nginx.简单说就是 FastCGI 实现了使用 Nginx 代理 php 请求的过程，将请求转发给 php-fpm：php 进程管理器。location / {
    fastcgi_pass  localhost:9000;
    # fastcgi_pass unix:/run/php/php7.3-fpm.sock;
    fastcgi_index index.php;
    
    fastcgi_split_path_info ^(.+?\.php)(.*)$;
    try_files $fastcgi_script_name =404;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include fastcgi_params;

    fastcgi_param HTTP_X-REAL-IP $remote_addr;
    fastcgi_param HTTP_X-FORWARED-FOR $proxy_add_x_forwarded_for;
    fastcgi_param HOST $http_host;
}$fastcgi_split_path_info 用来将 请求 url 拆分成两部分：php 文件之前的 $fastcgi_script_name 和之后的部分：$fastcgi_path_infofastcgi_pass 定义真正的用来处理 FastCGI 代理的服务，一般默认地址为：127.0.0.1:9000，可自定义指定为特定版本的phpfastcgi_param 定义 FastCGI 参数fastcgi_params 一般在 nginx 配置目录下，包含了常用的 php 需要设定的参数。总结下和 http 语法区别：fastcgi_pass 类似于 proxy_passfastcgi_param  类似于 proxy_set_header，注意 fastcgi_param 添加 http 请求头信息要加上 HTTP_ 前缀，如：HTTP_X-FORWARED-FOR关于 FastCGI 的详细分析参考：Understanding and Implementing FastCGI Proxying in NginxuWSGI web 服务器uWSGI 是一个独立的 web 服务器，和 nginx 是一个类型的应用。一般 uWSGI 作为后端服务器使用，用 nginx 代理来访问。uWSGI 可以用来部署 python 应用。之前我学习 django 的时候就使用过这个。未完待续。。。参考链接ngx_http_proxy_module 模块所有指令NGINX Reverse ProxyHTTP Load BalancingSecuring HTTP Traffic to Upstream Servers使用nginx的proxy_bind选项配置透明的反向代理Mapping Headers in Nginxngx_http_fastcgi_module 模块所有指令[]()</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1376.html">
<title>traceroute 路由 IP 查看</title>
<link>https://blog.niekun.net/archives/1376.html</link>
<dc:date>2020-03-20T09:00:07+08:00</dc:date>
<description>traceroute 是一种电脑网络工具。它可显示数据包在 IP 网络经过的路由器的 IP 地址。程序是利用增加存活时间（TTL）值来实现其功能的。每当数据包经过一个路由器，其存活时间就会减 1。当其存活时间是 0 时，主机便取消数据包，并发送一个ICMP TTL数据包给原数据包的发出者。traceroute 使用互联网控制信息协议(ICMP)实现，ICMP 依靠IP来完成它的任务，它是IP的主要部分。它与传输协议（如TCP和UDP）显著不同：它一般不用于在两点间传输数据。由于协议不同所以本地 http 代理对 traceroute 无效。现代 Linux 系统称为 tracepath，Windows 系统称为 tracert，Windows NT 系统有结合 ping 和 traceroute 的 pathping 工具。使用Linux可以使用 tracepath/traceroute 工具来测试，traceroute 可使用 apt 来安装，默认最多检测30个路由节点，超过的话就直接结束：root@niekun-bandwagon:~# tracepath github.com
 1?: [LOCALHOST]                                         pmtu 1500
 1:  no reply
 2:  173.254.196.25.static.quadranet.com                   0.980ms
 3:  lax1-fatpipe-1.it7.net                                0.395ms
 4:  69.12.69.1                                            0.539ms asymm  3
 5:  ae12.er4.lax112.us.zip.zayo.com                       0.515ms asymm  4
 6:  ae14.cr2.lax112.us.zip.zayo.com                      26.123ms asymm 11
 7:  ae2.cs1.sjc2.us.eth.zayo.com                         26.180ms asymm 11
 8:  ae3.cs1.sea1.us.eth.zayo.com                         30.307ms asymm 10
 9:  ae1.mcs1.sea1.us.eth.zayo.com                        26.299ms asymm  8traceroute to github.com (192.30.255.112), 30 hops max, 60 byte packets
 1  * * *
 2  173.254.196.25.static.quadranet.com (173.254.196.25)  1.172 ms  1.172 ms  1.161 ms
 3  lax1-fatpipe-1.it7.net (69.12.70.234)  0.220 ms lax1-fatpipe-1.it7.net (69.12.70.232)  0.341 ms lax1-fatpipe-1.it7.net (69.12.70.234)  0.193 ms
 4  ae12.er4.lax112.us.zip.zayo.com (64.124.85.221)  0.397 ms  0.422 ms 69.12.69.1 (69.12.69.1)  0.268 ms
 5  ae14.cr2.lax112.us.zip.zayo.com (64.125.30.74)  25.828 ms ae12.er4.lax112.us.zip.zayo.com (64.124.85.221)  0.364 ms  0.345 ms
 6  ae2.cs1.sjc2.us.eth.zayo.com (64.125.28.144)  35.091 ms ae14.cr2.lax112.us.zip.zayo.com (64.125.30.74)  26.043 ms  26.009 ms
 7  ae2.cs1.sjc2.us.eth.zayo.com (64.125.28.144)  34.909 ms  34.889 ms  34.832 ms
 8  ae1.mcs1.sea1.us.eth.zayo.com (64.125.28.133)  28.864 ms  26.124 ms  26.112 ms
 9  ae1.mcs1.sea1.us.eth.zayo.com (64.125.28.133)  28.448 ms  28.416 ms 64.125.188.97.IPYX-243981-001-ZYO.zip.zayo.com (64.125.188.97)  30.797 ms
10  * 64.125.188.97.IPYX-243981-001-ZYO.zip.zayo.com (64.125.188.97)  30.949 ms *
windows可以使用 tracert/pathping 工具来测试，pathping 多显示了个本地 IP，默认最多检测30个路由节点，超过的话就直接结束：PS C:\Users\Marco Nie&gt; tracert niekun.net

Tracing route to niekun.net [104.24.97.72]
over a maximum of 30 hops:

  1     5 ms     1 ms     1 ms  OrayBox.lan [27.168.1.1]
  2    67 ms   111 ms    81 ms  192.168.1.1
  3     3 ms     3 ms     4 ms  100.64.16.1
  4     4 ms     3 ms     4 ms  10.226.25.13
  5     9 ms     *        *     219.145.223.105
  6    33 ms    32 ms    33 ms  202.97.65.41
  7     *        *        *     Request timed out.
  8     *       42 ms   131 ms  202.97.12.50
  9   341 ms   197 ms   201 ms  202.97.41.50
 10   237 ms   232 ms   224 ms  202.97.92.45
 11   242 ms   252 ms   238 ms  218.30.54.214
 12   197 ms   195 ms   196 ms  104.24.97.72

Trace complete.PS C:\Users\Marco Nie&gt; pathping niekun.net

Tracing route to niekun.net [104.24.97.72]
over a maximum of 30 hops:
  0  Marco-vostro-14.lan [27.168.1.209]
  1  OrayBox.lan [27.168.1.1]
  2  192.168.1.1
  3  100.64.16.1
  4  10.226.25.13
  5  219.145.223.105
  6  202.97.65.41
  7  202.97.34.74
  8     *     202.97.12.50
  9  202.97.41.50
 10  202.97.92.45
 11  218.30.54.214
 12  104.24.97.72

Computing statistics for 300 seconds...</description>
</item>
</rdf:RDF>