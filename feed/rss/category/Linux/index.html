<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
xmlns="http://purl.org/rss/1.0/"
xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel rdf:about="https://blog.niekun.net/feed/rss/category/Linux/">
<title>Marco Nie - Linux</title>
<link>https://blog.niekun.net/category/Linux/</link>
<description></description>
<items>
<rdf:Seq>
<rdf:li resource="https://blog.niekun.net/archives/2572.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2570.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2457.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2454.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2451.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2448.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2321.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2320.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2310.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2303.html"/>
</rdf:Seq>
</items>
</channel>
<item rdf:about="https://blog.niekun.net/archives/2572.html">
<title>openwrt 修改进程 Socket 句柄数</title>
<link>https://blog.niekun.net/archives/2572.html</link>
<dc:date>2022-04-03T08:50:00+08:00</dc:date>
<description>最近在使用中发现一个软件 log 中出现大量的报错：/core/transport/internet/tcp: failed to accepted raw connections &gt; accept tcp [::]:18919: accept4: too many open files查询后知道这是进程占用的句柄数超出了系统最大值导致的。由于我的系统是 openwrt 所以下面介绍如何修改某个进程的最大句柄数限制。首先查询当前系统当前的句柄限制值：ulimit -n

1024也可以查询当前系统的其他所有限制参数：ulimit -a返回 1024 表示当前系统每个进程的限制值是 1024。然后我们查询下当前系统进程中占用情况：lsof -n |awk '{print $2}'|sort|uniq -c |sort -nr|more

     8790 2390
     41 2638
     27 1914
     26 1
     25 2127
     23 2166
     23 1976
     23 1704可以看到进程PID号 2390 就占用了 8790 个句柄，这肯定超出了系统限制，我们看看这个 2390 到底是那个程序：ps | grep 2390

 2390 root     5005m S    /usr/bin/v2ray -confdir /etc/v2ray/conf.d
 6815 root      1072 R    grep 2390发现的确是我报错的那个程序占用了这个进程。然后我们查询系统可以设置的最大句柄数：cat /proc/sys/fs/file-max

101238返回值说明当前系统可以设置最大句柄数为 101238.想要修改句柄数需要在对应进程的 procd init script 脚本修改内容，在 start_service 中增加：        procd_set_param limits core=&quot;unlimited&quot;
        procd_set_param limits nofile=&quot;101200&quot;
        procd_set_param limits nproc=&quot;101200&quot;limits 参数可以设置系统的一些限制值，openwrt 可用的限制值名称可以在官方文档找到：https://openwrt.org/docs/guide-developer/procd-init-scripts#service_parameters以上就将系统限制设置为一个较大的值，修改完成后重启这个进程即可。参考链接Linux命令：TCP连接高并发时Socket句柄数的修改procd-init-scripts#service_parametersprocd-init-script-example#advanced_optionsopenwrt procd init script 自启动脚本服务</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2570.html">
<title>iptables 配置透明代理注意事项</title>
<link>https://blog.niekun.net/archives/2570.html</link>
<dc:date>2022-04-03T08:33:00+08:00</dc:date>
<description>之前介绍过通过 dnsmasq 配合 iptables 实现对 ip 地址的流量过滤，dnsmasq 获取到流量后标记 ipset 然后通过 iptables 识别 ipset 然后将流量送往指定地址。通过 dnsmasq ipset 和 iptables 对域名流量的控制iptables 使用教程这里面存在一个问题就是流量回环问题，如果处理不好回导致 iptables 规则无限循环，尤其是在配置透明代理时候。iptables -t mangle -A PREROUTING -p tcp -m set --match-set gfwlist dst -j TPROXY --on-port 1081 --tproxy-mark 1
iptables -t mangle -A PREROUTING -p udp -m set --match-set gfwlist dst -j TPROXY --on-port 1081 --tproxy-mark 1
iptables -t mangle -A OUTPUT -p tcp -m set --match-set gfwlist dst -j MARK --set-mark 1
iptables -t mangle -A OUTPUT -p udp -m set --match-set gfwlist dst -j MARK --set-mark 1以上规则会将 指定 list 的流量发送到指定端口并打上 mark 标记，但是从目标地址返回数据后，数据流会再次匹配到以上规则导致再次将流量送往指定端口，导致无限循环。处理方法就是在目标地址获取到流量后，给流量打上 mark 标记，然后在 iptables 的最前面加上一条规则识别从目标地址返回的流量，直接 return 流量即可。例如目标地址处理后的流量标记为 mark 2，iptables 规则最前面增加一条规则：iptables -t mangle -I OUTPUT -j RETURN -m mark --mark 0x02-I 参数就是将规则放在在路由链的最前面。如果是通过脚本的方式配置 iptables，将开始的脚本内容修改如下即可：iptables -t mangle -A OUTPUT -j RETURN -m mark --mark 0x02

iptables -t mangle -A PREROUTING -p tcp -m set --match-set gfwlist dst -j TPROXY --on-port 1081 --tproxy-mark 1
iptables -t mangle -A PREROUTING -p udp -m set --match-set gfwlist dst -j TPROXY --on-port 1081 --tproxy-mark 1
iptables -t mangle -A OUTPUT -p tcp -m set --match-set gfwlist dst -j MARK --set-mark 1
iptables -t mangle -A OUTPUT -p udp -m set --match-set gfwlist dst -j MARK --set-mark 1这样就可以避免流量回环问题。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2457.html">
<title>安装 phpMyAdmin 管理 MySQL</title>
<link>https://blog.niekun.net/archives/2457.html</link>
<dc:date>2022-03-28T09:31:00+08:00</dc:date>
<description>phpMyAdmin 是一个 php 的免费工具，用来在 web 端管理 MySQL 数据库。它支持大部分的 MySQL 功能，比如：创建数据库，修改数据，管理用户权限，导入导出数据等。官方网站：https://www.phpmyadmin.net/GitHub 主页：https://github.com/phpmyadmin/phpmyadmin下面介绍在 Ubuntu 20.04 的安装及使用过程。安装首先确保已经安装好了 MySQL 和 php：apt install mysql-server php php-fpm php-mysql
然后安装 phpMyAdmin：apt install phpmyadmin
安装过程中会提示创建一个 mysql 管理账户 phpmyadmin，一般直接确认即可，然后设置账户密码。如果这一步跳过了创建账户，后期需要手动修改配置文件或手动创建一个 phpmyadmin 管理账户，否则登录可能会报错。配置 nginx安装完成后需要配置代理服务器，我使用的是 nginx，下面是 nginx 的配置文件部分：    location /phpmyadmin {
        root /usr/share/;
        index index.php index.html index.htm;
        location ~ ^/phpmyadmin/(.+\.php)$ {
            fastcgi_pass unix:/run/php/php7.4-fpm.sock;
            include fastcgi-php.conf;
        }
    }使用配置完成后就可以登陆 phpmyadmin 页面了，登录对应的 mysql 管理账户，可以是安装 phpmyadmin 时创建的账户也可以是我们之前使用 mysql 自己的账户：如果登录后发现下面有报错信息：Access denied for user 'phpmyadmin'@'localhost' (using password: NO)
可能就是安装的时候跳过了创建 phpmyadmin MySQL 账户的步骤，这里我们可以在终端手动创建报错信息中提示的用户名或者直接修改配置文件中定义的 phpmyadmin 管理账户。修改 /etc/phpmyadmin/config.inc.php，找到如下字段：$cfg['Servers'][$i]['controluser'] = 'user';
$cfg['Servers'][$i]['controlpass'] = 'password';将上面的用户名密码修改为 MySQL 中存在的账户即可。刷新页面之后应该就没有报错了。手动创建 MySQL 用户可以参考教程：https://blog.niekun.net/archives/23.html#title-3然后我们就可以正常使用 phpmyadmin 管理页面了，这里可以查看 database，导入导出数据等。参考链接phpMyAdmin ERROR: mysqli_real_connect(): (HY000/1045): Access denied for user 'pma'@'localhost' (using password: NO)</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2454.html">
<title>使用 rclone 管理网盘文件</title>
<link>https://blog.niekun.net/archives/2454.html</link>
<dc:date>2022-03-14T11:35:31+08:00</dc:date>
<description>之前介绍了通过 gdrive 在服务器上管理 Google drive 文件，实现服务器数据备份自动上传功能。最近发现有一个新的开源项目 rclone 支持更多的网盘，同时更新迭代速度也更快。GitHub 主页：https://github.com/rclone/rclone他支持的网盘列表：https://rclone.org/overview/下面介绍它的安装使用方法。安装Linux 下一键安装命令：curl https://rclone.org/install.sh | sudo bash
macos 通过 brew 安装：brew install rclone
配置首次运行执行初始化配置：rclone config
根据提示创建新 remote：No remotes found - make a new one
n) New remote
r) Rename remote
c) Copy remote
s) Set configuration password
q) Quit config
n/r/c/s/q&gt; n然后设置此连接名称，后续就是通过这个名称来操作不同的网盘的：name&gt; remote
下一步选择网盘类型，如果是 Google drive 选择 16：Type of storage to configure.
Choose a number from below, or type in your own value
[snip]
16 / Google Drive
   \ &quot;drive&quot;
[snip]
Storage&gt; 16下面的 id 和 secret 都默认回车即可：Google Application Client Id - leave blank normally.
client_id&gt;
Google Application Client Secret - leave blank normally.
client_secret&gt;下面设置可访问全部网盘文件，选择 1：Scope that rclone should use when requesting access from drive.
Choose a number from below, or type in your own value
 1 / Full access all files, excluding Application Data Folder.
   \ &quot;drive&quot;
 2 / Read-only access to file metadata and file contents.
   \ &quot;drive.readonly&quot;
   / Access to files created by rclone only.
 3 | These are visible in the drive website.
   | File authorization is revoked when the user deauthorizes the app.
   \ &quot;drive.file&quot;
   / Allows read and write access to the Application Data folder.
 4 | This is not visible in the drive website.
   \ &quot;drive.appfolder&quot;
   / Allows read-only access to file metadata but
 5 | does not allow any access to read or download file content.
   \ &quot;drive.metadata.readonly&quot;
scope&gt; 1下面几步都默认回车即可。注意到了 use auto config 的时候要选择 No，因为我们是远程 ssh 访问的服务器：Use auto config?
 * Say Y if not sure
 * Say N if you are working on a remote or headless machine or Y didn't work
y) Yes
n) No
y/n&gt; n下面会返回一个链接，复制链接到浏览器后，登录 google 账户给 rclone 授权。授权完成后会返回一个字符串码，粘贴回终端。后续几步默认回车即可，最后输入 q 退出 config。使用配置完成后我们就可以使用了，下面介绍一些基本语法。下面示例中网盘配置名称为 remote。列出网盘的所有文件：rclone ls remote:
列出一个文件夹内的所有文件：rclone ls remote:abc
创建一个文件夹：rclone mkdir remote:abc
rclone mkdir remote:abc/def
删除网盘内一个文件：rclone delete remote:abc/123.txt
删除一个文件夹：rclone rmdir remote:abc
复制本地一个文件到网盘：rclone copy 123.txt remote:abc
更多可用命令可以参考官方文档：https://rclone.org/docs/#subcommands</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2451.html">
<title>Ubuntu 18.04 升级 Ubuntu 20.04 记录</title>
<link>https://blog.niekun.net/archives/2451.html</link>
<dc:date>2022-03-12T15:32:00+08:00</dc:date>
<description>昨天决定把服务器的系统从 Ubuntu 18.04 升级到 Ubuntu 20.04，其中经历了不少问题点，下面记录下处理过程。首先就是升级当前系统所有包到最新：apt update &amp;&amp; apt upgrade -y
apt autoremove &amp;&amp; apt purge
然后安装升级需要的管理包，不过一般系统都是自带的：apt install update-manager-core
然后就可以更新系统了：do-release-upgrade
标准流程就是以上几步，但是在最后一步的时候问题就开始出现了。在执行升级命令后出现报警：Failed to connect to https://changelogs.ubuntu.com/meta-release-lts. Check your Internet connection or proxy settings
在查询一些资料后，原来是 ssl certificates 验证问题，系统无法鉴定上面的 https 链接证书是否有效就返回错误了。这个问题也是我这个系统的一个遗留问题，每次执行 wget 或 curl 下载东西的时候就会提示证书报错，需要通过附加指令跳过证书验证，但这就会存在安全问题了。解决方法就是更新本地证书库后添加 SSL_CERT_DIR 环境变量指向系统证书目录：update-ca-certificates --verbose --fresh
export SSL_CERT_DIR=/etc/ssl/certs
为了方便以后使用，将环境变量添加到 ~/.bashrc 文件中。这样就解决了 https 链接证书验证问题。然后先删除之前执行升级命令后错误内容：rm /var/lib/ubuntu-release-upgrader/release-upgrade-available
/usr/lib/ubuntu-release-upgrader/release-upgrade-motd
之后再次执行升级命令 do-release-upgrade。这时候报错信息变化了，这时候提示的是 python3 有问题，原因是我当前系统使用的是自己编译的 python 3.8，路径在 /opt 目录下。当时将系统软链接 /usr/bin/python 和 /usr/bin/python3 都指向了自己安装的 python，需要将他们恢复到指向系统内置的 python 程序。下面需要介绍下系统内 python 主程序和软链接的分布：python2 主应用程序为 /usr/bin/python2.7
python3 主应用程序为 /usr/bin/python3.6
pip 主程序为 /usr/bin/pip
pip3 主程序为 /usr/bin/pip3下面是默认的软链接及指向的应用程序：/usr/bin/python  -&gt;  /usr/bin/python2.7
/usr/bin/python2  -&gt;  /usr/bin/python2.7
/usr/bin/python3  -&gt;  /usr/bin/python3.6
/usr/local/bin/pip  -&gt;  /usr/bin/pip
/usr/local/bin/pip3  -&gt;  /usr/bin/pip3如果你修改过这些软链接到自己的 python 版本，就需要修改回来：ln -sf /usr/bin/python2.7 /usr/bin/python
ln -sf /usr/bin/python2.7 /usr/bin/python2
ln -sf /usr/bin/python3.6 /usr/bin/python3
ln -sf /usr/bin/pip /usr/local/bin/pip
ln -sf /usr/bin/pip3 /usr/local/bin/pip3
ldconfig以上问题都处理完后，再次执行升级命令，一切都正常了。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2448.html">
<title>解决 wget 下载时 certificates 证书报错问题</title>
<link>https://blog.niekun.net/archives/2448.html</link>
<dc:date>2022-03-11T16:48:00+08:00</dc:date>
<description>我的服务器上在使用 wget 或者 curl 等网络工具时，每次都提示类似下面的报错：ERROR: cannot verify github.com's certificate, issued by ‘CN=DigiCert High Assurance TLS Hybrid ECC SHA256 2020 CA1,O=DigiCert\\, Inc.,C=US’:
  Unable to locally verify the issuer's authority.
To connect to github.com insecurely, use `--no-check-certificate'.需要通过参数跳过证书检查，但是这样又有了安全风险。首先尝试更新本地证书文件：update-ca-certificates --verbose --fresh发现问题没有解决，原来是系统缺少了一个指向证书路径 /etc/ssl/certs 的环境变量，尝试添加：export SSL_CERT_DIR=/etc/ssl/certs再次测试 wget 命令，发现问题的确没有了。可以将上面的环境变量添加到系统 shell 配置文件中，我这里是 ~/.bashrc，添加后刷新一下即可：source ~/.bashrc在更新 Ubuntu18.04 到 20.04 时，也是这个问题导致的报错。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2321.html">
<title>openwrt 扩展根目录空间</title>
<link>https://blog.niekun.net/archives/2321.html</link>
<dc:date>2021-06-22T21:40:00+08:00</dc:date>
<description>我在软路由上通过 esxi 安装了 openwrt 作为路由系统。虚拟机分配了 5 GB 作为存储空间，但是安装完成后通过命令查看发现系统识别到的空间只有很小：root@OpenWrt:~# df -h
Filesystem                Size      Used Available Use% Mounted on
/dev/root               252.0M    241.4M      5.5M  98% /rom
tmpfs                   496.5M     68.0K    496.4M   0% /tmp
/dev/sda1                15.7M      3.8M     11.6M  25% /boot
/dev/sda1                15.7M      3.8M     11.6M  25% /boot
tmpfs                   512.0K         0    512.0K   0% /dev其中 /dev/root 是系统固件目录，不用考虑。/dev/sda* 就是系统实际可用的硬盘空间。我明明分配了 5 GB 空间给 openwrt 但是由于系统分区是在下载的固件中定义好的，所以其余空间就没有被识别。由于默认存储空间过小，当安装了过多的插件后，会提示空间不足导致无法安装更多插件：verify_pkg_installable: Only have 0kb available on filesystem /overlay, pkg luci-app-openvpn needs 9
opkg_install_cmd: Cannot install package luci-app-openvpn下面介绍如何将剩余空间挂在到 openwrt 中。首先安装需要的插件，注意顺序不能错：opkg update
opkg install block-mount e2fsprogs
opkg update
opkg install fdisk blkid然后配置存储空间，注意 fdisk 指令后的几个选项：fdisk -l

fdisk /dev/sda
m
n
p
&lt;默认,回车&gt; //–&gt;分区号为3
&lt;默认,回车&gt;
&lt;默认,回车&gt;
w

reboot重启后，格式化刚才建立的分区：mkfs.ext4 /dev/sda3
reboot重启后配置 fstab：uci add fstab mount

# 将下面第一行命令输出的 UUID 替换第二行命令后的 UUID
blkid -s UUID /dev/sda3 | cut -d\&quot; -f2
uci set fstab.@mount[-1].uuid=UUID

uci set fstab.@mount[-1].options=rw,sync,noatime
uci set fstab.@mount[-1].fstype=ext4
uci set fstab.@mount[-1].enabled_fsck=1
uci set fstab.@mount[-1].enabled=1
uci set fstab.@mount[-1].target=/
uci set fstab.@mount[-1].device=/dev/sda3
uci commit fstab然后根目录复制到新的分区下：mkdir /mnt/sda3
mount /dev/sda3 /mnt/sda3
mkdir -p /tmp/cproot
mount --bind / /tmp/cproot
tar -C /tmp/cproot -cvf - . | tar -C /mnt/sda3 -xf -

umount /tmp/cproot
umount /mnt/sda3然后启用引导：/etc/init.d/fstab enable
/etc/init.d/fstab start

reboot重启后再次查看系统分区信息：root@OpenWrt:~# df -h
Filesystem                Size      Used Available Use% Mounted on
/dev/root               252.0M    241.4M      5.5M  98% /rom
tmpfs                   496.5M      1.0M    495.5M   0% /tmp
/dev/sda3                 4.6G    257.2M      4.1G   6% /
/dev/sda1                15.7M      3.8M     11.6M  25% /boot
/dev/sda1                15.7M      3.8M     11.6M  25% /boot
tmpfs                   512.0K         0    512.0K   0% /dev可以看到 sda3 分区已经正常挂载了，后续可以继续安装需要的各种插件了。参考链接Vmware下openwrt虚拟机扩展根目录大小</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2320.html">
<title>理解 Linux shell 脚本的 2&amp;gt;&amp;amp;1</title>
<link>https://blog.niekun.net/archives/2320.html</link>
<dc:date>2021-05-31T18:33:51+08:00</dc:date>
<description>我们在编程中经常会使用一些固定语句来解决对应固定的问题，在 shell 脚本中一个被经常使用但不太好理解的短句就是 2&gt;&amp;1，例如：ls foo &gt; /dev/null 2&gt;&amp;1
下面我们一步步了解下这种结构的含义。I/O redirection 重定向简单理解，redirection 重定向就是将一个命令的 output 输出发送到另一个地方。例如，我们通过 cat 命令打印一个文件的内容到屏幕：$ cat foo.txt
foo
bar
baz我们也可以将输出的内容发送到其他地方，例如将内容重定向到另一个文件 file.txt:$ cat foo.txt &gt; output.txt

$ cat output.txt
foo
bar
baz执行第一条 cat 命令，我们不会看到任何输出信息，因为我们修改了 standard output (stdout)标准输出到一个文件，所以它就不会输出到屏幕了。需要注意的是还有另一个地方：standard error (stderr)标准错误，当有错误时会输出信息。所以当我们通过 cat 命令输出一个不存在的文件内容时：$ cat nop.txt &gt; output.txt
cat: nop.txt: No such file or directory以上示例中即使我们将 stdout 重定向到一个文件了，由于 output.txt 不存在，stderr 依然会输出错误信息到屏幕。因为我们重定向的只是 stdout 而不包括 stderr。file descriptors 文件描述器一个文件描述器是一个正整数，用来表示一个打开文件的。每个文件都有其各自的文件描述器。这里我们只需要知道 stdout 和 stderr 有其各自的文件描述器 id 定义了它们各自的地址。stdout 是 1，stderr 是 2。在之前的示例中，我们可以修改命令为如下结构：cat foo.txt 1&gt; output.txt
这里的 1 就是 stdout 的文件描述器，通过重定向语法 [FILE_DESCRIPTOR]&gt; 将 stdout 重定向到另一个文件。注意 1&gt; 可以简写为 &gt;。类似的，可以将 stderr 重定向到指定的目的地：$ cat nop.txt 2&gt; error.txt

$ cat error.txt
cat: nop.txt: No such file or directory这样就会将 error 存入 error.txt 文件，屏幕上不会输出任何信息。下面我们理解下 2&gt;&amp;1 的意义。我们使用 &amp;1 来指向 stdout 的重定向地址，所以 2&gt;&amp;1 表示重定向 stderr 到和 stdout 同样的重定向位置上。所以我们就可以通过下面示例的方法同时将 stdout 和 stderr 重定向到同一个文件中：$ cat foo.txt &gt; output.txt 2&gt;&amp;1

$ cat output.txt
foo
bar
baz

$ cat nop.txt &gt; output.txt 2&gt;&amp;1

$ cat output.txt
cat: nop.txt: No such file or directory总结有两个地方用来让程序发送输出内容：stdout，stderr可以单独定义两个输出的重定向目的地文件描述器用来识别 stdout (1) 和 stderr (2)command &gt; output 是 command 1&gt; output 的简写通过 &amp;[FILE_DESCRIPTOR] 指向一个文件描述器的重定向目标地址上2&gt;&amp;1 可以将 stderr 重定向到 stdout 同样的重定向地址上。反之亦然。参考链接Understanding Shell Script's idiom: 2&gt;&1In the shell, what does “ 2&gt;&1 ” mean?</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2310.html">
<title>通过 telegram-cli 命令行发送 telegram 消息</title>
<link>https://blog.niekun.net/archives/2310.html</link>
<dc:date>2021-05-18T20:08:00+08:00</dc:date>
<description>最近需要实现一个自动发送 telegram 消息的功能，GitHub 上发现一个 telegram 第三方的命令行终端：telegram-cli。可以实现我需要的功能。GitHub 主页：https://github.com/vysheng/tg测试平台为 Ubuntu 18.04安装有两种方法安装，第一种是通过 snap 应用商店来安装，第二种是从源码安装。snap 安装需要首先安装 snap 环境：sudo apt install snapd
然后就可以安装 telegram-cli：sudo snap install telegram-cli
默认安装路径为：/snap/bin/telegram-cli从源码编译稍微有些麻烦，因为 GitHub 上的源码最近更新是 2016 年，经过我的测试在 make 时会报错，查询后需要增加安装相关依赖库及调整配置选项后才能正常编译。首先安装依赖： sudo apt-get install libreadline-dev libconfig-dev libssl-dev lua5.2 liblua5.2-dev libevent-dev libjansson-dev libpython-dev zlib1g-dev libgcrypt20-dev make
下载仓库源码：git clone --recursive https://github.com/vysheng/tg.git &amp;&amp; cd tg
然后配置 configure：./configure --disable-openssl
最后编译：make
编译完成后可执行文件在项目源码的 bin 文件夹内。使用安装完成后需要配置账户信息，输入 telegram-cli 命令：telegram-cli
会提示输入手机号，验证码和密码等信息，按照提示输入完成后就会登录到 telegram-cli 中了。这时候通过 msg USERNAME message 的模式来给某个对话发送消息了：&gt; msg my_bot test
USERNAME 可以是某个用户，Bot 或者 channel。可以直接使用其名称或者通过@username的方式定义会话对象。经过我的测试，第一次登录到 telegram-cli 后，直接给某个对象发送消息会提示：error FAIL: 38: can not parse arg #1，但是我的用户名写的是没问题的。这时候需要首先执行一下 dialog_list 会输出当前登录账户的会话列表，可以看到每个会话的对象名称，这时候就可以正常通过使用对象名称或者 @username 来发送消息了。以上的操作都是在登录到 telegram-cli 中进行的，可以通过 quit 或 safe_quit 命令退出 telegram-cli 程序：&gt; quit
我们也可以直接通过 telegram-cli 命令发送给某个对象消息，需要 -e 参数加执行的命令，例如：telegram-cli -e &quot;msg @username message&quot;
建议执行时加上 -W参数以加载 dialog 列表，否则可能出现报警：error FAIL: 38: can not parse arg #1：telegram-cli -W -e &quot;msg @username message&quot;
使用 -D 参数可以关闭输出信息。使用 -U 参数可以自定义命令执行的用户。更多 telegram-cli 可用参数如下：# telegram-cli -h
telegram-cli Usage
  --phone/-u                           specify username (would not be asked during authorization)
  --rsa-key/-k                         specify location of public key (possible multiple entries)
  --verbosity/-v                       increase verbosity (0-ERROR 1-WARNIN 2-NOTICE 3+-DEBUG-levels)
  --enable-msg-id/-N                   message num mode
  --config/-c                          config file name
  --profile/-p                         use specified profile
  --log-level/-l                       log level
  --sync-from-start/-f                 during authorization fetch all messages since registration
  --disable-auto-accept/-E             disable auto accept of encrypted chats
  --lua-script/-s                      lua script file
  --wait-dialog-list/-W                send dialog_list query and wait for answer before reading input
  --disable-colors/-C                  disable color output
  --disable-readline/-R                disable readline
  --alert/-A                           enable bell notifications
  --daemonize/-d                       daemon mode
  --logname/-L &lt;log-name&gt;              log file name
  --username/-U &lt;user-name&gt;            change uid after start
  --groupname/-G &lt;group-name&gt;          change gid after start
  --disable-output/-D                  disable output
  --tcp-port/-P &lt;port&gt;                 port to listen for input commands
  --udp-socket/-S &lt;socket-name&gt;        unix socket to create
  --exec/-e &lt;commands&gt;                 make commands end exit
  --disable-names/-I                   use user and chat IDs in updates instead of names
  --enable-ipv6/-6                     use ipv6 (may be unstable)
  --help/-h                            prints this help
  --accept-any-tcp                     accepts tcp connections from any src (only loopback by default)
  --disable-link-preview               disables server-side previews to links
  --bot/-b                             bot mode
  --json                               prints answers and values in json format
  --permanent-msg-ids                  use permanent msg ids
  --permanent-peer-ids                 use permanent peer idscrontab 定时任务可以通过 crontab 设置定时自动发送消息。首先编辑执行脚本，将如下示例代码保存在 test.sh 中：#!/bin/sh
LOGFILE=&quot;/home/log/submit_code.log&quot;

telegram-cli -U root -W -e &quot;msg USERNAME test&quot; &gt;&gt; ${LOGFILE}以上脚本通过 root 用户执行发送消息，会首先加载 dialog list 然后发送消息，最后退出会话。脚本中我配置了将发送信息保存在 log 文件中，也可以不保存日志，去掉最后的 &gt;&gt; ${LOGFILE} 即可。然后配置 crontab 定时任务，可以参考我的教程：https://blog.niekun.net/archives/461.html需要注意的是通过 snap 安装的 telegram-cli 可执行程序目录默认在 /snap/bin 目录下。需要将路径定义到 crontab 配置文件中才可以正常识别到脚本中的 telegram-cli 命令。编辑 /etc/crontab 文件：SHELL=/bin/sh
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/snap/bin
HOME=/root

10  9  *  *  * root bash   /path/to/test.sh注意 PATH 参数最后添加的 /snap/bin，如果是通过其他方式安装的 telegram-cli，需要根据实际情况定义可执行程序路径。保存文件后，会自动在 9 点 10 分自动执行 test.sh 脚本。参考链接How to install telegram-clion Ubuntu使用telegram-cli命令行发送信息LXK0301京东签到脚本-自动提交互助码FAIL: 38: can not parse arg #1</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2303.html">
<title>在 Ubuntu 中加载 smb 共享目录为本地路径</title>
<link>https://blog.niekun.net/archives/2303.html</link>
<dc:date>2021-04-29T10:15:00+08:00</dc:date>
<description>最近在家里搭建了局域网环境，使用了一个海康威视 H99 网络驱动器作为家里的存储中心。它可以实现 smb 和 arp 协议的共享，从而满足我的基本需求。访问 smb 共享目录的方法是在文件浏览器中通过：smb://xxx.xxx.xxx.xxx 的模式输入地址，然后就会将网络驱动器挂载到本地，显示为一个本地网络路径。之后就可以正常的管理远程文件内容了。但是我发现在使用一些下载软件的时候，无法直接将共享目录作为下载目录设置，只能选择本地的目录地址。此时就需要将 smb 网络共享路径映射为本地地址才可以实现上述需求。下面介绍在 Ubuntu 中配置。在 Linux 中，可以通过 mount 命令的 cifs 选项将 smb 共享加载到本地驱动器的某个地方。Common Internet File System (CIFS) 是一个网络文件共享协议，它是 smb 的一种格式。安装首先我们安装 CIFS 工具：sudo apt install cifs-utils
加载加载一个远程 smb 共享和加载本地文件系统类似，使用 mount 命令实现。需要首先创建一个加载目录服务于远程路径：sudo mkdir /mnt/h99_share
通过下面命令加载某个 smb 共享：sudo mount -t cifs -o username=win_share_user,password=win_share_password //xxx.xxx.xxx.xxx/usbshare /mnt/h99_share
其中 username 和 password 是访问远程设备的账户密码，需要在配置 smb 共享时设置好。后面需要定义远程地址及共享目录，最后指定本地映射的目录地址。默认情况下加载的共享目录所有者为 root 且权限为 777。通过 dir_mode 和 file_mode 参数可以自定义挂载的目录权限：sudo mount -t cifs -o username=win_share_user,password=win_share_password,dir_mode=0755,file_mode=0755 //xxx.xxx.xxx.xxx/usbshare /mnt/h99_share
如果当前登录用户不是 root 用户，则可能你无法修改共享目录下的内容，可以在挂载时指定用户和用户组：sudo mount -t cifs -o username=win_share_user,password=win_share_password,uid=marco,gid=marco,dir_mode=0755,file_mode=0755 //xxx.xxx.xxx.xxx/usbshare /mnt/h99_share
以上示例中，我们设置用户和用户组为 marco，这样当本地用户登录为 marco 时就可以读写共享目录的内容了。自动挂载以上命令挂载的目录在系统重启后会取消。在 /etc/fstab 文件中可以定义指定的路径及文件系统在系统启动时自动挂载。下面我们在此文件中定义自动挂载配置，需要指定远程地址，共享目录以及本地映射地址：# &lt;file system&gt;             &lt;dir&gt;          &lt;type&gt; &lt;options&gt;                                                                                           &lt;dump&gt;  &lt;pass&gt;                             
//xxx.xxx.xxx.xxx/usbshare  /mnt/h99_share  cifs  username=win_share_user,password=win_share_password,uid=marco,gid=marco,dir_mode=0755,file_mode=0755  0       0配置好 fatab 文件后，我们就可以使用以下命令直接挂载对应远程目录了：sudo mount /mnt/h99_share
mount 命令会自动读取 /etc/fstab 文件并挂载对应远程地址目录。并且下次系统重启会自动挂载此目录。卸载目录通过 umount 命令可以下载已经加载的文件系统：sudo umount /mnt/h99_share
如果当前加载的文件正在被其他进程使用，则 umount 卸载会失败，提示文件正忙。查询当前加载目录正在被那个进程使用，可以通过 fuser 命令实现：fuser -m /mnt/h99_share
可以根据输出信息使用 kill 结束对应进程，然后就可以正常卸载了。参考链接How to Mount Windows Share on Linux using CIFSForcing Linux to Unmount a Filesystem Reporting “device is busy”</description>
</item>
</rdf:RDF>