<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
xmlns="http://purl.org/rss/1.0/"
xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel rdf:about="https://blog.niekun.net/feed/rss/category/web/">
<title>Marco Nie - web</title>
<link>https://blog.niekun.net/category/web/</link>
<description></description>
<items>
<rdf:Seq>
<rdf:li resource="https://blog.niekun.net/archives/1666.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1489.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1378.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1443.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1432.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1375.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1300.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1249.html"/>
<rdf:li resource="https://blog.niekun.net/archives/1199.html"/>
<rdf:li resource="https://blog.niekun.net/archives/820.html"/>
</rdf:Seq>
</items>
</channel>
<item rdf:about="https://blog.niekun.net/archives/1666.html">
<title>Linux 下使用 OptiPNG 压缩图片</title>
<link>https://blog.niekun.net/archives/1666.html</link>
<dc:date>2020-07-14T17:25:00+08:00</dc:date>
<description>最近越来也发现自己的博客加载图片变慢了，由于我很多教程是教 PS 的，会使用到很多图片和截图，所以影响尤其明显。每张图片小则 400Kb 大则 2-3Mb，对于网络浏览不太友好。可以直接在服务器上进行图片压缩，用到的工具是 OptiPNG。OptiPNG home page：http://optipng.sourceforge.net/编译安装我选择从源码编译安装，这样可以直接使用最新版本。如何从源码编译程序可以参考我的文章：https://blog.niekun.net/archives/883.html首先从官网下载源码到 vps 并解压：cd /tmp
wget http://prdownloads.sourceforge.net/optipng/optipng-0.7.7.tar.gz
tar xvf optipng-0.7.7.tar.gz
新建安装路径：mkdir /opt/optipng-0.7.7
ln -s /opt/optipng-0.7.7 /opt/optipng
configure & make：cd /tmp/optipng-0.7.7
./configure --prefix=/opt/optipng-0.7.7
make
make install
测试是否可以执行：/opt/optipng/bin/optipng
创建系统链接：ln -s /opt/optipng/bin/optipng /usr/local/bin/optipng
使用可以使用命令查看处理前处理后的图片体积：ls -lh a.png
压缩一张 png 图片：optipng a.png
压缩目录下的所有 png 图片：optipng *.png
可以自定义压缩等级：Optimization levels:
    -o0         &lt;=&gt;     -o1 -nx -nz                             (0 or 1 trials)
    -o1         &lt;=&gt;     -zc9 -zm8 -zs0 -f0                      (1 trial)
                (or...) -zc9 -zm8 -zs1 -f5                      (1 trial)
    -o2         &lt;=&gt;     -zc9 -zm8 -zs0-3 -f0,5                  (8 trials)
    -o3         &lt;=&gt;     -zc9 -zm8-9 -zs0-3 -f0,5                (16 trials)
    -o4         &lt;=&gt;     -zc9 -zm8 -zs0-3 -f0-5                  (24 trials)
    -o5         &lt;=&gt;     -zc9 -zm8-9 -zs0-3 -f0-5                (48 trials)
    -o6         &lt;=&gt;     -zc1-9 -zm8 -zs0-3 -f0-5                (120 trials)
    -o7         &lt;=&gt;     -zc1-9 -zm8-9 -zs0-3 -f0-5              (240 trials)
    -o7 -zm1-9  &lt;=&gt;     -zc1-9 -zm1-9 -zs0-3 -f0-5              (1080 trials)
Notes:
    The combination for -o1 is chosen heuristically.
    Exhaustive combinations such as &quot;-o7 -zm1-9&quot; are not generally recommended.
Examples:
    optipng file.png                                            (default speed)
    optipng -o5 file.png                                        (slow)
    optipng -o7 file.png                                        (very slow)</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1489.html">
<title>使用 echo 模块输出 nginx 变量</title>
<link>https://blog.niekun.net/archives/1489.html</link>
<dc:date>2020-03-30T15:43:00+08:00</dc:date>
<description>最近在学习 nginx 的反向代理，在处理请求和响应的时候，需要处理 header 头信息用到了很多 nignx 变量，但是在传递给代理服务器时，我不知道我设置的 proxy_set_header 等信息是否设置正确，以及其他用到的变量到底当前值是多少我也不知道。调试起来很费劲。发现一个第三方 nginx 模块：echo，可以方便的输出信息，利用这一模块可以实现变量值读取到 html，调试方便了很多。echo GitHub 主页：https://github.com/openresty/echo-nginx-module编译echo 模块需要从源码编译 nginx 时使用指令：--add-module= 加入，源码编译 nginx 及加入第三方模块参考我的教程：Nginx 安装/编译教程使用echo 使用命令很简单：server{
    listen 80;
    server_name 127.0.0.1;

    location /echo {
        default_type text/plain;
        echo 'remote address: $remote_addr';
        echo 'remote_port: $remote_port';
    }
}default_type text/plain 指令设置响应内容的格式，不设置的话浏览器访问会返回下载文件而不是网页。执行 curl 127.0.0.1/echo 或浏览器访问 127.0.0.1/echo 路径就会看到 echo 定义的内容。**注意如果在 echo 指令下面定义了其他 html 页面或者 proxy_pass 反向代理，则 echo 的内容会被覆盖，如果 echo 指令在  location 段的最后，则会显示 echo 指令的内容。**</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1378.html">
<title>NGINX Reverse Proxy 反向代理的使用</title>
<link>https://blog.niekun.net/archives/1378.html</link>
<dc:date>2020-03-30T11:05:00+08:00</dc:date>
<description>Proxying is typically used to distribute the load among several servers, seamlessly show content from different websites, or pass requests for processing to application servers over protocols other than HTTP.nginx 可以将一个客户端的请求反向代理到其他地址/端口，从客户端上看不到代理过程。方向代理的常用来处理服务器上部署的多个网络服务，根据请求呈现不同网页内容，转发请求到其他应用程序等。支持转发的协议有：  HTTP，FastCGI, uwsgi, SCGI, and memcached。不同于 nginx 的重定向 return/rewrite/try_fiels 功能，反向代理对于客户端是不可见的，关于重定向的语法参考：https://blog.niekun.net/archives/195.html下面介绍 ngx_http_proxy_module 模块的使用方式。语法proxy_pass 指令将请求转发到其他代理服务器。转发一个 http 请求到另一个地址：location /some/path/ {
    proxy_pass http://www.example.com/link/;
}以上示例将访问 location 段的请求转发到特定地址，这里有几个规则需要注意：1.代理地址如果不写明 location 段，则转发请求 location 到新的地址：location /some/path/ {
    proxy_pass http://www.example.com;
}以上规则下，访问 /some/path/.test.html 时，会转发到 http://www.example.com/some/path/.test.htmllocation ~ \.php {
    proxy_pass http://127.0.0.1:8000;
}以上规则下，访问 /some/path/test.php 时，会转发到 127.0.0.1:8000/some/path/test.php2.代理地址包含新的 location 时会替换掉请求 location 部分：location /some/path/ {
    proxy_pass http://www.example.com/new/;
}以上规则下，访问 /some/path/test.html 时，会转发到 http://www.example.com/new/test.html，注意 http://www.example.com/ 和 http://www.example.com 不同，也属于包含根路径 location 段的。proxy_pass 语法用来转发给 http 服务，还支持转发给其他协议的服务：fastcgi_pass 转发给 FastCGI server 如 php 服务uwsgi_pass 转发给 uwsgi server 如 python 服务scgi_pass 转发给 SCGI servermemcached_pass 转发给 memcached server转发的服务地址可以用一个 upstream 组来实现负载均衡：http {
    upstream backend {
        server backend1.example.com;
        server backend2.example.com;
        server 192.0.0.1 backup;
    }
    
    server {
        ...
        location / {
            proxy_pass http://backend;
        }
    }
}以上是一个简单的负载均衡代理转发示例。关于 upstream 详细使用参考官方教程proxy_redirect 响应头 location/refresh 重定向当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location/Refresh 字段。语法结构：proxy_redirect default;
proxy_redirect off;
proxy_redirect redirect replacement;
默认设置是：proxy_redirect default。http 响应头的 location 段 HTTP Location 是在两种情况使用在响应头中：要求网页浏览器加载其他网页(域名转址)。在这种情况下，应该使用HTTP状态码3xx发送Location头。提供有关新创建资源位置的信息。在这种情况下，应该使用HTTP状态码201或202发送Location头。通过修改 location 可以让客户端接收到响应后，访问重定向到新的 location。更详细的关于重定向/刷新请求头概念，需要理解 http 协议的结构，查看我的教程：HTTP 协议结构如果设置：server {listen 8080;
servername frontend;

proxy_redirect http://localhost:8000/two/ http://frontend:8080/one/;
...}代理服务器返回的 http 头信息：HTTP/1.1 302 Found
Location: http://localhost:8000/two/some/uri/
则返回给客户端的 Location 段被重写为: http://frontend:8080/one/some/uri/，客户端接收到后就会去重新访问这个新的地址。server 名也可以被省略：proxy_redirect http://localhost:8000/two/ /
以上指令返回给客户端的 Location 段被重写为: http://frontend:8080/some/uri/proxy_redirect 默认设置值为：default，它会自动根据 server location 段和 proxy_pass 地址来修改头信息，以下两种写法效果一样：location /one/ {
    proxy_pass     http://localhost:8000/two/;
    proxy_redirect default;

location /one/ {
    proxy_pass     http://localhost:8000/two/;
    proxy_redirect http://localhost:8000/two/ /one/;以上两种写法都是将返回 location 头信息中 http://localhost:8000/two/ 修改为 http://frontend:8080/one/redirect 和 replacement 都可以包含参数：proxy_redirect http://$proxy_host:8000/ $scheme$host:$server_port/;
rederect 可以使用正则匹配：proxy_redirect ~^(http://[^:]+):\d+(/.+)$ $1$2;
proxy_redirect ~*/user/([^/]+)/(.+)$      http://$1.example.com/$2;
可以同时写多个 proxy_redirect 指令来处理不同的重定向地址。使用 proxy_redirect off 具有最高优先级，会取消当前同一级的所有 proxy_redirect 指令。一个完整例子：server {
    listen           8080;
    server_name      127.0.0.1;

    location /return {
        return 301 https://niekun.net;
    }
    location /proxy {
        proxy_pass  $scheme://$http_host/return;
        proxy_redirect https://niekun.net /echo;
    }
    location /echo {
        default_type text/plain;
        echo 'remote address: $remote_addr';
    }
}代理过程：客户端访问：http://127.0.0.1:8080/proxynginx 转发到：http://127.0.0.1:8080/return代理服务器响应 301 重定向到：https://niekun.net，http 头的 location 值为：https://niekun.netnginx 将 http 头的 location 修改为：http://127.0.0.1:8080/echonginx 将修改后的响应内容发送给客户端客户端根据响应再次访问：http://127.0.0.1:8080/echo转发请求头信息默认情况下，nginx 反向代理时会舍弃原始请求头中的空字符串项，并重新设定两个请求头内容：Host 和 Connection：Host -&gt; $proxy_host  也就是 proxy_pass 里的 hostConnection -&gt; close关于 http 请求头 header 的可定义的项目参考我的教程：HTTP 协议结构想要设置或修改传递给代理服务的请求头，使用 proxy_set_header 指令：location /some/path/ {
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header Accept-Encoding &quot;&quot;;
    proxy_pass http://localhost:8000;
}以上示例的处理结果是：设置 Host 为本 server 的host 地址而不是转发地址设置 X-Real-IP 为客户端 IP 地址，用来识别访问服务的客户信息清空 Accept-Encoding 的内容mapping headers 动态请求头内容proxy_set_header 支持使用内部变量来定义，也可以使用 map 指令配合自定义参数来根据请求清空动态设置相关 header 内容，注意 map 指令要写在 http 段：map $http_cloudfront_forwarded_proto $cloudfront_proto {
    default &quot;http&quot;;
    https &quot;https&quot;;
}
server {
    ...
    location / {
        proxy_set_header X-Forwarded-Proto $cloudfront_proto;
        proxy_pass http://app;
        proxy_redirect off;
        ...
    }
}以上示例中 $http_cloudfront_forwarded_proto 是已知变量，$cloudfront_proto 是我自定义的变量，使用 map 指令来根据前者的值设置后者的值，然后在 proxy_set_header 设置。map 指令支持以两个因变量来给终变量赋值,语法示例如下：map &quot;$http_cloudfront_forwarded_proto:$http_x_forwarded_proto&quot; $cloudfront_proto {
    default &quot;http&quot;;
    &quot;:https&quot; &quot;https&quot;;
    &quot;https:&quot; &quot;https&quot;;
    &quot;https:http&quot; &quot;https&quot;;
    &quot;http:https&quot; &quot;https&quot;;
    &quot;https:https&quot; &quot;https&quot;;
}如果用户访问时加了代理或者网站有 CDN，$remote_addr 的值就不是用户真实 IP 了。客户端也可以伪造 X-Forwarded-For 信息，使用 map 指令提取用户真实 IP，注意 map 指令要写在配置文件的 http 段：map $http_x_forwarded_for  $client_real_ip {
    default                         $remote_addr;
    ~^(([0-9\.]+),\s?)*([0-9\.]+)$  $3;
}

server {
    echo 'remote address: $client_real_ip';
}如果 $http_x_forwarded_for 没有匹配到则赋值为 $remote_addr，如果匹配到了则提取最后一个 IP。$client_real_ip 变量就是真是客户端的 IP 地址。关于 $http_x_forwarded_for 和 $proxy_add_x_forwarded_for 参考我的文章：获取用户真实 IP in Nginxbuffers 缓存区默认情况下 nginx 缓存来自 proxy server 的响应内容。nginx 会一直在内部缓存来自代理服务器的响应内容直到内容接收完成，然后才发送给客户端。缓存能够帮助减轻客户端的压力，但会浪费服务器的资源和响应。但是打开缓存功能的另一个好处是当客户端再次进行一个缓存过的请求时，nginx 可以快速的返回已经在缓存区的内容。使用 proxy_buffering 指令控制缓存打开/关闭。默认是 on 状态。proxy_buffers 指令控制缓存区数量和缓存大小。第一个来自代理服务器的响应会缓存到单独的区域，proxy_buffer_size 指令控制这一区域的大小：location /some/path/ {
    proxy_buffers 16 4k;
    proxy_buffer_size 2k;
    proxy_pass http://localhost:8000;
}以上示例会给 来自代理服务器：http://localhost:8000 的响应建立 16 个缓存区，每个区域 4kb 空间，第一个响应缓存区 2kb 空间。如果关闭缓存，来自代理服务器的响应会即时发送给客户端，对于想要快速响应的使用场景可以关闭缓存：location /some/path/ {
    proxy_buffering off;
    proxy_pass http://localhost:8000;
}设置出口 IP 地址默认情况下 nginx 向 proxy 上游发起请求连接，代理服务器看到的请求 IP 地址来自 nignx 服务器地址。有时候 web 服务器会设置只允许特定 IP 地址的访问，可以通过 proxy_bind 指令来修改，nginx 用户必须是 root 才行：user root;
...
http{
    ...
    server {
        location /app1/ {
            proxy_bind proxy_bind $remote_addr transparent;
            proxy_pass http://example.com/app1/;
        }
    }
}以上示例中，代理服务器看到的请求来源就会是真正的访问客户端 IP 地址,也就是实现了透明代理。nginx 配置后还需要配置 iptables 路由表来处理代理服务器响应内容：新建一个链，把过来的tcp包都打上标记。新建一个路由表100，让有标记的包都走表100。在路由表100加入一个默认路由，把所有包都扔到lo网卡上去。      #### 新建一个 DIVERT 给包打标签
     sudo iptables -t mangle -N DIVERT;
     sudo iptables -t mangle -A DIVERT -j MARK --set-mark 1;
     sudo iptables -t mangle -A DIVERT -j ACCEPT;

     #### 把tcp的包给DIVERT处理
     sudo iptables -t mangle -A PREROUTING -p tcp -m socket -j DIVERT;

     #### 有标签的包去查名为 100 的路由表
     sudo ip rule add fwmark 1 lookup 100

     #### 100的路由表里就一条默认路由，把所有包都扔到lo网卡上去
     sudo ip route add local 0.0.0.0/0 dev lo table 100;具体实现我还不太懂，后期再研究下。以上就是 http 代理服务器基本使用，下面简单介绍其他集中代理服务器的语法。fastcgi 代理服务器Nginx must rely on a separate PHP processor to handle PHP requests. Most often, this processing is handled with php-fpm, a PHP processor that has been extensively tested to work with Nginx.简单说就是 FastCGI 实现了使用 Nginx 代理 php 请求的过程，将请求转发给 php-fpm：php 进程管理器。location / {
    fastcgi_pass  localhost:9000;
    # fastcgi_pass unix:/run/php/php7.3-fpm.sock;
    fastcgi_index index.php;
    
    fastcgi_split_path_info ^(.+?\.php)(.*)$;
    try_files $fastcgi_script_name =404;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    include fastcgi_params;

    fastcgi_param HTTP_X-REAL-IP $remote_addr;
    fastcgi_param HTTP_X-FORWARED-FOR $proxy_add_x_forwarded_for;
    fastcgi_param HOST $http_host;
}$fastcgi_split_path_info 用来将 请求 url 拆分成两部分：php 文件之前的 $fastcgi_script_name 和之后的部分：$fastcgi_path_infofastcgi_pass 定义真正的用来处理 FastCGI 代理的服务，一般默认地址为：127.0.0.1:9000，可自定义指定为特定版本的phpfastcgi_param 定义 FastCGI 参数fastcgi_params 一般在 nginx 配置目录下，包含了常用的 php 需要设定的参数。总结下和 http 语法区别：fastcgi_pass 类似于 proxy_passfastcgi_param  类似于 proxy_set_header，注意 fastcgi_param 添加 http 请求头信息要加上 HTTP_ 前缀，如：HTTP_X-FORWARED-FOR关于 FastCGI 的详细分析参考：Understanding and Implementing FastCGI Proxying in NginxuWSGI web 服务器uWSGI 是一个独立的 web 服务器，和 nginx 是一个类型的应用。一般 uWSGI 作为后端服务器使用，用 nginx 代理来访问。uWSGI 可以用来部署 python 应用。之前我学习 django 的时候就使用过这个。未完待续。。。参考链接ngx_http_proxy_module 模块所有指令NGINX Reverse ProxyHTTP Load BalancingSecuring HTTP Traffic to Upstream Servers使用nginx的proxy_bind选项配置透明的反向代理Mapping Headers in Nginxngx_http_fastcgi_module 模块所有指令[]()</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1443.html">
<title>百度云网盘直链获取及下载</title>
<link>https://blog.niekun.net/archives/1443.html</link>
<dc:date>2020-03-27T11:46:00+08:00</dc:date>
<description>众所周知，现在百度盘非会员下载速度十分慢，还要求必须使用他的客户端下载，我的资料现在也基本不会存在百度云了。但是在下载已经保存在上面的资源或者网络别人分享的资源，还是偶尔要用到，而我又对百度十分的讨厌，也不会去充值会员，所以研究了下如何解决非会员的限速问题。BaiduPCS-GoBaiduPCS-Go 是我之前一直使用的工具，他是 GO 语言编写的命令行工具，需要登录你的账号使用，集成下载/上传等功能。就是一个第三方命令行客户端。他可以设置缓存/并发数/user agent等，理论上可以加速下载。GitHub 主页(作者已删除)：https://github.com/iikira/BaiduPCS-Gofork：https://github.com/Erope/BaiduPCS-Go可以下载 release 页面发布的版本，也可以使用源码自己编译，go 语言编译教程参考我的文章：https://blog.niekun.net/archives/468.html打开 BaiduPCS-Go 客户端，进入命令行界面，登录完成后可以输入 help 指令查看支持的命令。----
  BaiduPCS-Go - 百度网盘客户端 for windows/amd64

USAGE:
  BaiduPCS-Go.exe [global options] command [command options] [arguments...]

VERSION:
  v3.6.1-devel

DESCRIPTION:
  BaiduPCS-Go 使用Go语言编写的百度网盘命令行客户端, 为操作百度网盘, 提供实用功能.
  具体功能, 参见 COMMANDS 列表

  特色:
    网盘内列出文件和目录, 支持通配符匹配路径;
    下载网盘内文件, 支持网盘内目录 (文件夹) 下载, 支持多个文件或目录下载, 支持断点续传和高并发高速下载.

  ---------------------------------------------------
  前往 https://github.com/iikira/BaiduPCS-Go 以获取更多帮助信息!
  前往 https://github.com/iikira/BaiduPCS-Go/releases 以获取程序更新信息!
  ---------------------------------------------------

  交流反馈:
    提交Issue: https://github.com/iikira/BaiduPCS-Go/issues
    邮箱: i@mail.iikira.com

AUTHOR:
  iikira/BaiduPCS-Go: https://github.com/iikira/BaiduPCS-Go

COMMANDS:
    tool           工具箱
    help, h, ?, ？  Shows a list of commands or help for one command
  其他:
    bg           管理后台任务
    clear, cls   清空控制台
    env          显示程序环境变量
    run          执行系统命令
    sumfile, sf  获取本地文件的秒传信息
    update       检测程序更新
  百度帐号:
    login    登录百度账号
    loglist  列出帐号列表
    logout   退出百度帐号
    su       切换百度帐号
    who      获取当前帐号
  百度网盘:
    cd                      切换工作目录
    cp                      拷贝文件/目录
    createsuperfile, csf    手动分片上传—合并分片文件
    download, d             下载文件/目录
    export, ep              导出文件/目录
    fixmd5                  修复文件MD5
    locate, lt              获取下载直链
    ls, l, ll               列出目录
    match                   测试通配符
    meta                    获取文件/目录的元信息
    mkdir                   创建目录
    mv                      移动/重命名文件/目录
    offlinedl, clouddl, od  离线下载
    pwd                     输出工作目录
    quota                   获取网盘配额
    rapidupload, ru         手动秒传文件
    recycle                 回收站
    rm                      删除文件/目录
    search, s               搜索文件
    share                   分享文件/目录
    tree, t                 列出目录的树形图
    upload, u               上传文件/目录
  配置:
    config  显示和修改程序配置项

GLOBAL OPTIONS:
  --verbose      启用调试 [%BAIDUPCS_GO_VERBOSE%]
  --help, -h     show help
  --version, -v  print the version

COPYRIGHT:
  (c) 2016-2019 iikira.执行 login 指令，登录百度账户，根据提示输入密码及验证码。登录完成后可以使用 ls cd 等命令来访问目录及文件。执行 config 命令查看当前配置信息：运行 BaiduPCS-Go config set 可进行设置配置

当前配置:
  名称                 值             描述                                             建议值                                                                                                                     
  appid             421937       百度 PCS 应用ID
  cache_size      256.00KB      下载缓存, 如果硬盘占用高或下载速度慢, 请尝试 调大此值     1KB ~ 256KB                                                                                                                
  max_parallel         64       下载最大并发量                                         50 ~ 500                                                                                                                   
  max_upload_parallel  64       上传最大并发量                                         1 ~ 100                                                                                                                    
  max_download_load    3         同时进行下载文件的最大数                               1 ~ 5                                                                                                                      
  max_download_rate    不限制    限制最大下载速度, 0代表不限制
  max_upload_rate      不限制    限制最大上传速度, 0代表不限制
  savedir      C:\Users\Marco Nie\Downloads          下载文件的储存目录
  enable_https         true      启用 https                                             true                                                                                                                       
  user_agent           Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36  Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36      浏览器标识
  pcs_ua                         PCS 浏览器标识
  pan_ua     netdisk;2.2.51.6;netdisk;10.0.63;PC;android-android    Pan 浏览器标识    netdisk;2.2.51.6;netdisk;10.0.63;PC;android-android                 
  proxy                         设置代理, 支持 http/socks5 代理
  local_addrs                   设置本地网卡地址, 多个地址用逗号隔开执行 config set --名称=value 可以修改设置值。下载指令是 d file_name。我当前使用 BaiduPCS-Go 速度非常慢，在下载时使用参数 --verbose 和 --status 查看详细信息，发现链接都是错误的，经过查询发现可能是 appid 的问题，我的账号可能上了黑名单了，需要修改 appid 来修复。找了半天网上提供的 appid 都没法用，这个 python 小程序可以扫描可用的 appid：https://gist.github.com/pcmid/5818b1165bc3f5f2088e19299278a613from __future__ import print_function

import requests
import threading

import sys


def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)


class GetterTread(threading.Thread):
    def __init__(self, thread_id, app_id, times=1000):
        threading.Thread.__init__(self)

        self.__thread_id = thread_id

        self.__URL = &quot;http://pcs.baidu.com/rest/2.0/pcs/file?app_id={}&amp;method=list&amp;path=%2F&quot;

        with open(&quot;./BDUSS.txt&quot;) as f:
            BDUSS = f.readline()
            self.__COOKIES = {&quot;BDUSS&quot;: BDUSS}

        self.app_id = app_id
        self.times = times

    def run(self):
        current_id = self.app_id
        while current_id - self.app_id &lt; self.times:  # 250000:
            url = self.__URL.format(current_id)

            try:
                r = requests.get(url, cookies=self.__COOKIES)
                if r.status_code == 200:
                    print(current_id)
            except Exception:
                eprint(&quot;Exception: &quot; + str(current_id))

            current_id += 1
            # print(&quot;id &quot; + str(self.__thread_id) + &quot; over&quot;)


if __name__ == '__main__':

    start_app_id = 300000
    times = 1000

    threads_list = []

    while start_app_id &lt; 500000:
        thread = GetterTread(start_app_id, start_app_id, times)
        thread.start()
        threads_list.append(thread)
        start_app_id += times

    # print(&quot;size: &quot; + str(len(threads_list)))

    for thread in threads_list:
        thread.join()需要在目录下放一个 BDUSS.txt，里面填上你的账号的 BDUSS 获取 BDUSS 的方法参考网盘直链下载助手BaiduPCS-Go 慢慢失效后，我开始找寻其他的有效方法，发现有一个网盘直链下载助手挺好用的。官网：https://www.baiduyun.wiki/GitHub 主页：https://github.com/syhyz1990/baiduyun这是一个油猴脚本，需要在 chrome 安装 Tampermonkey 脚本管理器，在 chrome 安装 tampermonkey安装好管理器后，访问 GitHub脚本，会自动跳转到 tampermonkey 安装界面，然后点击安装即可。进入百度云盘，会出现一个下载助手按钮：勾选想要下载的资源，点击下载助手，里面有几个选项：第一个是直接获取 api 下载链接，可以在浏览器或其他下载软件粘贴链接即可下载：第二个是 aria2 下载链接，可以导入 aria2 进行下载，关于 aria2 的安装参考我的教程：https://blog.niekun.net/archives/1199.html安装好 aria2 后还需要安装网盘万能助手 chrome 插件才能使用这个功能。插件地址：https://www.baiduyun.wiki/download.html插件安装步骤：下载好 zip 包后解压到文件夹chrome 访问：chrome://extensions/ 右边打开 develop mode，点击 load unpacked 打开解压的文件夹就自动安装了关闭 develop mode重启浏览器第三个是远程 aria2 rpc 下载，也是需要安装 aria2 并启用 rpc，然后点击 rpc 配置，设置参数：点击显示链接可以直接发送到 aria2：下载客户端推荐：aria2：https://blog.niekun.net/archives/1199.htmlIDM：https://www.internetdownloadmanager.com/ 可以设置最大链接数到 32 来提高下载速度 download - option - connectionxdown：https://xdown.org/ 可以识别 aria2 的链接</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1432.html">
<title>HTTP 协议结构</title>
<link>https://blog.niekun.net/archives/1432.html</link>
<dc:date>2020-03-24T08:43:00+08:00</dc:date>
<description>The Hypertext Transfer Protocol (HTTP) is an application protocol for distributed, collaborative, hypermedia information systems.[1] HTTP is the foundation of data communication for the World Wide Web, where hypertext documents include hyperlinks to other resources that the user can easily access, for example by a mouse click or by tapping the screen in a web browser.以上说明摘录自 Wikipedia，HTTP 全称为超文本传输协议，设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。通过HTTP或者HTTPS协议请求的资源由统一资源标识符（Uniform Resource Identifiers，URI）来标识。构成HTTP是一个客户端（用户）和服务端（网站）之间请求和应答的标准，通常使用TCP协议。有时也承载于TLS或SSL协议层之上，这个时候，就成了我们常说的HTTPS：HTTP协议永远都是客户端发起请求，服务器回送响应。HTTP是一个无状态的协议。协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态。从另一方面讲，打开一个服务器上的网页和你之前打开这个服务器上的网页之间没有任何联系。可以使用 connection: Keep-Alive 来保留 tcp 握手连接。一次HTTP操作称为一个事务，其工作过程可分为四步：首先客户机与服务器需要建立连接。只要单击某个超级链接，HTTP的工作开始。建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URI）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客户机与服务器断开连接。HTTP是基于传输层的TCP协议，而TCP是一个端到端的面向连接的协议。所谓的端到端可以理解为进程到进程之间的通信。所以HTTP在开始传输之前，首先需要建立TCP连接，而TCP连接的过程需要三次握手：可以使用 Wireshark 网络协议分析工具来查看一个握手过程：https://www.wireshark.org/打开 Wireshark，点击 capture - options，上方选择当前连接外网的硬件，我选择 WiFi，在 capture filter 里设置监听地址：tcp port http:在浏览器访问：http://baidu.com，记得如果使用了代理的话先关掉。在 wireshark 里就会显示报文信息：可以通过颜色区分报文种类，绿色是 tcp 报文，黑色是有问题的报文。如果报文过多可以使用上面的 filter 过滤有用信息。上面的报文显示了握手的过程：前三个 tcp 连接分别是客户端发出连接请求，服务端回应客户端，客户端回应服务端确认然后客户端发起一个 http 页面 request 请求服务端发出 tcp 确认请求服务端发送 response http 数据 200 状态码客户端发出 tcp 确认下面主要分析 request 和 response 的 http 数据。request 请求tcp 握手成功后，客户端就通过发送 request 开始请求 http 页面。发出的请求信息（message request）结构如下:请求行（例如GET /images/logo.gif HTTP/1.1，表示从/images目录下请求logo.gif这个文件）请求头（例如Accept-Language: en）空行其他消息体请求行和标题必须以&lt;CR&gt;&lt;LF&gt;作为结尾。空行内必须只有&lt;CR&gt;&lt;LF&gt;而无其他空格。在HTTP/1.1协议中，所有的请求头，除Host外，都是可选的。一个最简单的 request：GET / HTTP/1.1
Host: www.bing.com末尾有一个空行。第一行指定方法、资源路径、协议版本；第二行是在1.1版里必带的一个header作用于指定主机。上面访问 http://baidu.com 的request 全部内容如下：(在 wireshark 点击 request http 报文可查看)    GET / HTTP/1.1\r\n
    Host: news.baidu.com\r\n
    Connection: keep-alive\r\n
    Upgrade-Insecure-Requests: 1\r\n
    DNT: 1\r\n
    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\r\n
    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\n
    Referer: https://www.baidu.com/\r\n
    Accept-Encoding: gzip, deflate\r\n
    Accept-Language: en,en-US;q=0.9,zh-CN;q=0.8,zh;q=0.7,zh-TW;q=0.6\r\n
    Cookie: BIDUPSID=DFBCEB19126518FE5B14DE02435939DF; PSTM=1585012306; BAIDUID=DFBCEB19126518FEC81AB23A0B7A652F:FG=1; H_PS_PSSID=30971_1426_31118_21108_30824_26350\r\n
    \r\n
    [Full request URI: http://news.baidu.com/]
    [HTTP request 1/3]
    [Response in frame: 23]
    [Next request in frame: 599]请求方法HTTP/1.1协议中共定义了八种方法（也叫“动作”）来以不同方式操作指定的资源：GET 向指定的资源发出“显示”请求。使用GET方法应该只用在读取数据，GET上要在url之外带一些参数就只能依靠url上附带querystring。HEAD 与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。POST 向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。PUT 向指定资源位置上传其最新内容。DELETE 请求服务器删除Request-URI所标识的资源。TRACE 回显服务器收到的请求，主要用于测试或诊断。OPTIONS 这个方法可使服务器传回该资源所支持的所有HTTP请求方法。CONNECT HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接。当某个请求所针对的资源不支持对应的请求方法的时候，服务器应当返回状态码405（Method Not Allowed），当服务器不认识或者不支持对应的请求方法的时候，应当返回状态码501（Not Implemented）。最常用的就是 GET 和 POST 方法。GET和POST的区别：GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&相连，如EditPosts.aspx?name=test1&id=123456. POST方法是把提交的数据放在HTTP包的Body中。GET提交的数据大小有限制，最多只能有1024字节（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制。GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码。版本HTTP/0.9 已过时。只接受GET一种请求方法，没有在通讯中指定版本号，且不支持请求头。不支持 POSTHTTP/1.0 这是第一个在通讯中指定版本号的HTTP协议版本，至今仍被广泛采用，特别是在代理服务器中。HTTP/1.1 持久连接被默认采用，并能很好地配合代理服务器工作。还支持以管道方式在同时发送多个请求，降低线路负载提高传输速度。HTTP/2 当前版本，于2015年5月作为互联网标准正式发布。请求头HTTP 头字段根据实际用途被分为以下 4 种类型：通用头字段(英语：General Header Fields)请求头字段(英语：Request Header Fields)响应头字段(英语：Response Header Fields)实体头字段(英语：Entity Header Fields)常见的请求头字段：Accept 能够接受的回应内容类型：Accept: text/plainConnection 该浏览器想要优先使用的连接类型：Connection: keep-aliveContent-Type 请求体的多媒体类型：Content-Type: application/x-www-form-urlencodedHost 服务器的域名(用于虚拟主机 )，以及服务器所监听的传输控制协议端口号：Host: en.wikipedia.org:80User-Agent - 浏览器的浏览器身份标识字符串：ser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:12.0) Gecko/20100101 Firefox/21.0If-Modified-Since 把浏览器端缓存页面的最后修改时间发送到服务器，如果和服务器文件时间一致，那么返回304：If-Modified-Since: Thu, 09 Feb 2012 09:07:57 GMTpragma 指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝，在HTTP/1.1版本中，它和Cache-Control: no-cache作用一模一样：pragma: no-cacheCache-Control 指定请求和响应遵循的缓存机制：Cache-Control: no-cacheCookie 之前由服务器通过 Set- Cookie （下文详述）发送的一个 超文本传输协议Cookie常见的非标准请求头字段：DNT 请求某个网页应用程序停止跟踪某个用户：DNT: 1 (DNT启用)X-Forwarded-For 一个事实标准 ，用于标识某个通过超文本传输协议代理或负载均衡连接到某个网页服务器的客户端的原始互联网地址：X-Forwarded-For: 129.78.138.66, 129.78.64.103X-Forwarded-Host 一个事实标准 ，用于识别客户端原本发出的 Host 请求头部：X-Forwarded-Host: en.wikipedia.orgX-Forwarded-Proto 一个事实标准，用于标识某个超文本传输协议请求最初所使用的协议：X-Forwarded-Proto: https更多请求头字段参考：wikepediaresponse 响应服务端发出 tcp 确认后，发出 response 响应 http 页面。发出的响应信息（message request）结构如下:状态行（例如HTTP/1.1 200 OK，表示从信息传递成功）响应头（例如Content-Length: 3059）空行传递实体内容(可以为空)下面是一个 http 页面的响应实例：    HTTP/1.1 200 OK\r\n
    Content-Type: text/html; charset=utf-8\r\n
    Server: GitHub.com\r\n
    Last-Modified: Fri, 22 Jan 2016 02:52:30 GMT\r\n
    ETag: W/&quot;56a1996e-2d27&quot;\r\n
    Access-Control-Allow-Origin: *\r\n
    Expires: Tue, 24 Mar 2020 06:32:29 GMT\r\n
    Cache-Control: max-age=600\r\n
    Content-Encoding: gzip\r\n
    X-Proxy-Cache: MISS\r\n
    X-GitHub-Request-Id: EAD6:198D:D9A2C:E5FDD:5E79A724\r\n
    Content-Length: 4509\r\n
    Accept-Ranges: bytes\r\n
    Date: Tue, 24 Mar 2020 06:22:29 GMT\r\n
    Via: 1.1 varnish\r\n
    Age: 0\r\n
    Connection: keep-alive\r\n
    X-Served-By: cache-hnd18730-HND\r\n
    X-Cache: MISS\r\n
    X-Cache-Hits: 0\r\n
    X-Timer: S1585030950.603621,VS0,VE171\r\n
    Vary: Accept-Encoding\r\n
    X-Fastly-Request-ID: 806211821134676c48d8c7c6ed9cee2a6bad952d\r\n
    \r\n
    [HTTP response 1/5]
    [Time since request: 0.405424000 seconds]
    [Request in frame: 2595]
    [Next request in frame: 2604]
    [Next response in frame: 2623]
    [Request URI: http://zq210wl.github.io/imgs/noise.png]
    Content-encoded entity body (gzip): 4509 bytes -&gt; 11559 bytes
    File Data: 11559 bytes
    &lt;!DOCTYPE HTML&gt;
    &lt;html&gt;
    &lt;head&gt;
      &lt;meta charset=&quot;utf-8&quot;&gt;
      ...
    &lt;/head&gt;
    &lt;body&gt;
      ...
    &lt;/body&gt;状态行响应行结构为：当前HTTP版本号，3位数字组成的状态代码，以及描述状态的短语，彼此由空格分隔。状态码状态代码的第一个数字代表当前响应的类型：1xx消息——请求已被服务器接收，继续处理2xx成功——请求已成功被服务器接收、理解、并接受3xx重定向——需要后续操作才能完成这一请求4xx请求错误——请求含有词法错误或者无法被执行5xx服务器错误——服务器在处理某个正确请求时发生错误详细的状态码介绍参考：https://blog.niekun.net/archives/192.html响应头HTTP 头字段根据实际用途被分为以下 4 种类型：通用头字段(英语：General Header Fields)请求头字段(英语：Request Header Fields)响应头字段(英语：Response Header Fields)实体头字段(英语：Entity Header Fields)常见的响应头字段：Allow 对于特定资源有效的动作：Allow: GET, HEADAge 这个对象在代理缓存中存在的时间，以秒为单位：Age: 12Connection 针对该连接所预期的选项：Connection: keep-aliveContent-Language 内容所使用的语言：Content-Language: daExpires 指定一个日期/时间，超过该时间则认为此回应已经过期：Expires: Thu, 01 Dec 1994 16:00:00 GMTLocation 用来进行重定向，或者在创建了某个新资源时使用：Location: http://www.w3.org/pub/WWW/People.htmlRefresh 用于设定可定时的重定向跳转。右边例子设定了5秒后跳转至：Refresh: 5; url=http://www.w3.org/pubServer服务器的名字：Server: Apache/2.4.1 (Unix)Upgrade 要求客户端升级到另一个协议：Upgrade: HTTP/2.0Set-Cookie 设置 HTTP cookie记录客户端身份：Set-Cookie: UserID=JohnDoe; Max-Age=3600; Version=1常见的非标准回应字段：X-Powered-By 表明用于支持当前网页应用程序的技术：X-Powered-By: PHP/5.4.0X-Content-Duration 指出音视频的长度，单位为秒：X-Content-Duration: 42.666详细的响应头字段参考：Wikipedia响应头的 location 段HTTP Location 是在两种情况使用在响应头中：要求网页浏览器加载其他网页(域名转址)。在这种情况下，应该使用HTTP状态码3xx发送Location头。提供有关新创建资源位置的信息。在这种情况下，应该使用HTTP状态码201或202发送Location头。示例：HTTP/1.1 302 Found
Location: http://www.example.org/index.php客户端请求的 URL 被服务端重定向到 http://www.example.org/index.php.客户端请求：GET /blog HTTP/1.1
Host: www.example.com服务端响应：HTTP/1.1 302 Found
Location: /articles/该位置 /blog 被客户端定向到 http://www.example.com/articles/.解决HTTP无状态的问题使用Cookie来实现：服务器给每个Session分配一个唯一的JSESSIONID，并通过Cookie发送给客户端。当客户端发起新的请求的时候，将在Cookie头中携带这个JSESSIONID。这样服务器能够找到这个客户端对应的Session。使用URL回写来实现：URL回写是指服务器在发送给浏览器页面的所有链接中都携带JSESSIONID的参数，这样客户端点击任何一个链接都会把JSESSIONID带会服务器。如果直接在浏览器输入服务端资源的url来请求该资源，那么Session是匹配不到的。URI 统一资源标志符统一资源标识符（英语：Uniform Resource Identifier，缩写：URI）在电脑术语中是一个用于标识某一互联网资源名称的字符串。该种标识允许用户对网络中（一般指万维网）的资源通过特定的协议进行交互操作。URI的最常见的形式是统一资源定位符（URL），经常指定为非正式的网址。更罕见的用法是统一资源名称（URN），其目的是通过提供一种途径。用于在特定的名字空间资源的标识，以补充网址。通用URI的格式如下：[协议名]://[用户名]:[密码]@[主机名]:[端口]/[路径]?[查询参数]#[片段ID]下面是两个常见的 URI 构成：
                   hierarchical part
        ┌───────────────────┴─────────────────────┐
                    authority               path
        ┌───────────────┴───────────────┐┌───┴────┐
  abc://username:password@example.com:123/path/data?key=value&amp;key2=value2#fragid1
  └┬┘   └───────┬───────┘ └────┬────┘ └┬┘           └─────────┬─────────┘ └──┬──┘
scheme  user information     host     port                  query         fragment


  urn:example:mammal:monotreme:echidna
  └┬┘ └──────────────┬───────────────┘
scheme              path以 https://zh.wikipedia.org:80/w/index.php?title=Special:随机页面#ABC 为例, 其中：https，是协议；zh.wikipedia.org，是服务器；80，是服务器上的网络端口号；/w/index.php，是路径；?title=Special:随机页面，是询问。#ABC，是片段　参考连接超文本传输协议HTTP头字段HTTP_Location统一资源标志符一资源定位符HTTP协议详解</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1375.html">
<title>wkhtmltopdf 将 html为 pdf</title>
<link>https://blog.niekun.net/archives/1375.html</link>
<dc:date>2020-03-18T12:58:56+08:00</dc:date>
<description>一般浏览器都可以将当前页面输出为 pdf，但当有很多个 html 文件时一个一个转换就很麻烦了，可以使用 wkhtmltopdf 命令行工具来实现自动化批量转换。wkhtmltopdf and wkhtmltoimage are open source (LGPLv3) command line tools to render HTML into PDF and various image formats using the Qt WebKit rendering engine. These run entirely "headless" and do not require a display or display service.wkhtmltopdf 官网：https://wkhtmltopdf.org/GitHub 主页：https://github.com/wkhtmltopdf/wkhtmltopdf下载在 release 页面下载对应系统最新版：https://github.com/wkhtmltopdf/wkhtmltopdf/releases我要安装到 Ubuntu 18.04，所以下载：wkhtmltox_0.12.5-1.bionic_amd64.deb查看 Ubuntu 系统代号可以使用命令：lsb_release -c
安装下载的 deb 包，用以下命令进行安装：dpkg -i wkhtmltox_0.12.5-1.bionic_amd64.deb
使用支持 url 或 本地 html 转换：wkhtmltopdf http://bing.com bing.pdf
wkhtmltopdf path/to/test.html index.pdf
配合 find 命令可以实现批量转换：find path/to/html -name '*.html' -exec wkhtmltopdf {} {}.pdf \;
mkdir pdf/
find path/to/html -name '*.pdf' -exec mv {} pdf/ \;find 命令详细用法参考：https://blog.niekun.net/archives/543.html可以使用 wget 命令下载某个网站到本地，然后使用上面命令批量转换：wget -m -p -k URL
-m, –mirror 等价于 -r -N -l inf -nr-p：下载所有html文件适合显示的元素-k, –convert-links 转换非相对链接为相对链接,将文档链接都转换成本地的</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1300.html">
<title>网站压力测试 loader.io</title>
<link>https://blog.niekun.net/archives/1300.html</link>
<dc:date>2020-03-10T15:51:50+08:00</dc:date>
<description>免费的网站压力测试平台 loader.io官网：https://loader.io/</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1249.html">
<title>关于手机端无法使用 typecho 的搜索框解决</title>
<link>https://blog.niekun.net/archives/1249.html</link>
<dc:date>2020-03-03T22:34:48+08:00</dc:date>
<description>最近自己做了一个 typecho 的主题，主要是手机端的页面优化和字体优化，使用了 bootstrap 来渲染，主题在 GitHub 上开源：https://github.com/nie11kun/TypechoAwesome但是测试发现搜索框无法正确搜索，总是返回主页。今天终于发现问题所在了，由于我的网站使用的 NS 服务是 cloudflare 的，在当时设置的时候，把移动端 Mobile Redirect 优化选择上了，每次访问网站都会重定向到 m.niekun.net，估计是 cf 做了什么精简，导致功能丢失，把 Mobile Redirect 关闭就正常了。具体修改路径是 speed - optimisation：页面拉到最下方，将 Mobile Redirect 关掉：再次访问主页，就不会重定向到 m.niekun.net 而是 niekun.net 了。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/1199.html">
<title>aria2 使用指南</title>
<link>https://blog.niekun.net/archives/1199.html</link>
<dc:date>2020-02-28T17:10:00+08:00</dc:date>
<description>aria2 是一款轻量级的下载器，支持 HTTP/HTTPS, FTP, SFTP, BitTorrent and Metalink 等多种协议。它有如下特点：多节点链接：下载一个文件可以同时链接多个源来提速轻量级：占用系统资源极少，一般下载任务内存占用 10mb 内全功能的 BitTorrent 客户端：支持 DHT, PEX, Encryption, Magnet URI, Web-Seeding, Selective Downloads, Local Peer Discovery and UDP tracker支持 metalink 链接支持远程控制：支持 RPC 界面控制 aria2 进程官网：https://aria2.github.io/GitHub 主页：https://github.com/aria2/aria2webui-aria2：https://github.com/ziahamza/webui-aria2aria2 下载安装从官方发布页下载对应平台的最新版包，我是 Windows x64 系统下载了 aria2-1.35.0-win-64bit-build1.zip：https://github.com/aria2/aria2/releases/
解压压缩包到本地，我的解压目录是：C:\Users\Marco Nie\Application\aria2aria2c.exe 就是 aria2 主程序。命令行使用aria2 原生支持命令行控制，它的控制语句形式由 主程序 - 选项参数 - 链接 构成：aria2c [&lt;OPTIONS&gt;] [&lt;URI&gt;|&lt;MAGNET&gt;|&lt;TORRENT_FILE&gt;|&lt;METALINK_FILE&gt;]
全部的可用参数参考官方文档：https://aria2.github.io/manual/en/html/aria2c.html#synopsis下面简单介绍几个常用的下载命令修改下载目录终端里切换到 aria2 目录，使用下面命令将文件下载到 /home 目录下，使用参数 --dir 控制下载目录：aria2c --dir=/home http://www.file.zip
注意如果不定义 dir 目录，则默认下载到当前用户根目录。下载指定文档内的链接aria2c --input-file=dl.txt --max-concurrent-downloads=5 --dir=/home
下载 dl.txt 内所有的链接，同时下载5个文件。多路链接下载aria2c --split=5 http://www.file.zip
同时建立 5 个链接来下载这个文件，如果链接源速度不够快，这样可以达到提速效果。远程控制aric2c --enable-rpc=true --rpc-listen-all=true
开启远程控制，默认端口为 6800 可使用 --rpc-listen-port 参数修改。以上命令执行后，可以使用 JSON-RPC/XML-RPC 来控制，下一章节会详细介绍。指定配置文件aria2c --conf-path=/home/aria2.conf http://www.file.zip
当设置的 option 参数很多的时候，每次启动都敲入大量的命令就很麻烦了，可以将所有需要的配置参数放到一个配置文件里，使用 --conf-path 加载配置文件就可以了。由于命令行方式控制不便于个人使用，所以这里介绍以 webUI 的方式控制 aria2。webui-aria2webui-aria2 是一个官方推荐的 web RPC 控制器，图形化的界面方便管理进程。GitHub 主页：https://github.com/ziahamza/webui-aria2下载仓库包到本地：解压压缩包到本地，我放在了 aria2 文件夹目录，在 docs 文件夹下启动 indix.html 就打开了 web 控制面板：这时候页面会报错，因为 aria2 源程序还没有启动，命令行执行一下指令启动 rpc：aric2c --enable-rpc=true --rpc-listen-all=true
刷新页面就可以连接到 aria2 了。下面系统介绍配置文件的建立和断点续传的使用。配置文件在 aria2 根目录下新建四个文件：aria2.conf，aria2.session，aria2.log，dht.dataria2.conf：aria2 的配置参数文件，定义了 aria2 的启动参数aria2.session：会话信息记录文件，用来进行断点续传aria2.log：日志文件dht.dat：DHT 网络路由缓存文件路径，BT 相关aria2.conf 推荐设置内容如下(自行修改里面的目录)：# 文件的保存路径(可使用绝对路径或相对路径), 默认: 当前启动位置
dir=C:\Users\Marco Nie\Downloads

# 启动的时候，从会话文件中读取下载任务
input-file=C:\Users\Marco Nie\Application\aria2\aria2.session

# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件
save-session=C:\Users\Marco Nie\Application\aria2\aria2.session

# DHT 路由文件路径，BT 相关
dht-file-path=C:\Users\Marco Nie\Application\aria2\dht.dat

# log 日志文件，没有的话输出到 stdout
log=C:\Users\Marco Nie\Application\aria2\aria2.log

# 日志级别 debug, info, notice, warn or error. Default: debug
log-level=warn

#下载完成后执行脚本
# on-download-complete=执行脚本

# Windows 下不关闭的话会出现 Timeout while contacting DNS servers
async-dns=false

# 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M
#disk-cache=32M
#disk-cache=32M

# 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc
# 预分配所需时间: none &lt; falloc &lt; trunc &lt; prealloc
# falloc和trunc则需要文件系统和内核支持
# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项
file-allocation=prealloc

# 断点续传
continue=true

## 下载连接相关 ##

# 最大同时下载任务数, 运行时可修改, 默认:5
max-concurrent-downloads=10

# 同一服务器连接数, 添加时可指定, 默认:1 最大16
max-connection-per-server=16

# 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M
# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载
min-split-size=10M

# 单个任务最大线程数, 添加时可指定, 默认:5
split=5

# 整体下载速度限制, 运行时可修改, 默认:0
#max-overall-download-limit=0

# 单个任务下载速度限制, 默认:0
#max-download-limit=0

# 整体上传速度限制, 运行时可修改, 默认:0
#max-overall-upload-limit=0

# 单个任务上传速度限制, 默认:0
#max-upload-limit=0

# 禁用IPv6, 默认:false
disable-ipv6=true

# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0
save-session-interval=60

## RPC相关设置 ##

# 启用RPC, 默认:false
enable-rpc=true

# 添加任务后默认暂停下载
pause=false

# 允许所有来源, 默认:false
rpc-allow-origin-all=true

# 允许外网访问, 默认:false
rpc-listen-all=true

# save torrent or metalink meta data to --dir
rpc-save-upload-metadata=true

# 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项
rpc-secret=&lt;设置自定义 token，要和远程设置一样&gt;

# RPC监听端口, 端口被占用时可以修改, 默认:6800
rpc-listen-port=6800

## BT/PT下载相关 ##

# 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true
follow-torrent=true

# BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999
#listen-port=51413

# 单个种子最大连接数, 默认:55
bt-max-peers=55

# 打开DHT功能, PT需要禁用, 默认:true
enable-dht=true

# 打开IPv6 DHT功能, PT需要禁用
#enable-dht6=false

# DHT网络监听端口, 默认:6881-6999
dht-listen-port=6881-6999

# 本地节点查找, PT需要禁用, 默认:false
bt-enable-lpd=true

# 种子交换, PT需要禁用, 默认:true
enable-peer-exchange=true

# 每个种子限速, 对少种的PT很有用, 默认:50K
#bt-request-peer-speed-limit=50K

# 客户端伪装, PT需要
#peer-id-prefix=-TR2770-
user-agent=Transmission/2.92
#user-agent=netdisk;4.4.0.6;PC;PC-Windows;6.2.9200;WindowsBaiduYunGuanJia

# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0
seed-ratio=1.0

#作种时间大于30分钟，则停止作种
seed-time=30

# 强制保存会话, 话即使任务已经完成, 默认:false，BitTorrent seeding which is recognized as completed state
#force-save=false

# BT校验相关, 默认:true
#bt-hash-check-seed=true

# 继续之前的BT任务时, 无需再次校验, 默认:false
bt-seed-unverified=true

# 保存磁力链接元数据为种子文件(.torrent文件), 默认:false
bt-save-metadata=true

# 加密传输 防止吸血
bt-force-encryption=true

# 添加自定义的 bt tracker 地址，从 https://github.com/ngosang/trackerslist 找最新的链接
bt-tracker=udp://tracker.coppersurfer.tk:6969/announce,udp://tracker.leechers-paradise.org:6969/announce,udp://tracker.opentrackr.org:1337/announce,udp://p4p.arenabg.com:1337/announce,udp://9.rarbg.to:2710/announce,udp://9.rarbg.me:2710/announce,udp://tracker.internetwarriors.net:1337/announce,udp://exodus.desync.com:6969/announce,udp://tracker.tiny-vps.com:6969/announce,udp://tracker.torrent.eu.org:451/announce,udp://tracker.cyberia.is:6969/announce,udp://open.stealth.si:80/announce,udp://open.demonii.si:1337/announce,udp://denis.stalker.upeer.me:6969/announce,udp://tracker.sbsub.com:2710/announce,udp://tracker.moeking.me:6969/announce,udp://retracker.lanta-net.ru:2710/announce,udp://ipv4.tracker.harry.lu:80/announce,udp://explodie.org:6969/announce,udp://zephir.monocul.us:6969/announce启动 aria2上述文件设置完毕后，就可以启动 aria2 了，在终端执行如下命令：cd /to/aria2/path
aria2c --conf-path=aria2.conf
然后启动 webui-aria2 的 index.html 网页，根据 aria2.conf 配置文件情况设置 setting - connection 内容，就可以正常使用了。我将 webui-aria2 托管到了我的网站：https://webui-aria2.niekun.net。但是发现如果 webui 是 https 的就无法连接上 aria2 了，查了下好像是 web 加密问题，所以还是把 webui-aria2 放在本地使用吧。外网远程控制如果服务器在内网，可能需要进行内网穿透，可以参考我的 frp 教程，建立 http 转发：https://niekun.net/archives/539.htmlfrpc 配置示例片段：[aria2]
type = http
local_ip = 127.0.0.1
local_port = 6800
subdomain = aria2
use_encryption = true
use_compression = true如果按照我 frp 教程配置 nginx 代理 frp 的话，完成后就可以通过：https://aria2.youdomain.net:443 来控制 aria2 了。开机自启动可以建立脚本来实现开机自启动。Windows在 aria2 目录新建 bat 文件，内容如下：@echo off
if &quot;%1&quot; == &quot;h&quot; goto begin
mshta vbscript:createobject(&quot;wscript.shell&quot;).run(&quot;&quot;&quot;%~nx0&quot;&quot; h&quot;,0)(window.close)&amp;&amp;exit
:begin
REM
cd %USERPROFILE%\Application\aria2
aria2c --conf-path=aria2.conf
exit建立脚本快捷方式，将快捷方式放到开机启动文件夹内即可，Windows 10 开机启动目录为：%APPDATA%\Microsoft\Windows\Start Menu\Programs\Startup下载完成执行脚本使用配置文件里的 on-download-complete 选项，可以实现自定义的功能。在 aria2 下载完成后，执行 on-download-complete 脚本时会自动传递三个参数：GID GID is an ID of a download which aria2c uses to identify a particular download下载文件个数文件路径示例：$ cat hook.sh
#!/bin/sh
echo &quot;Called with [$1] [$2] [$3]&quot;
$ aria2c --on-download-complete hook.sh http://example.org/file.iso
Called with [1] [1] [/path/to/file.iso]Linux 下可以编写 bash 脚本。windows 下可以执行 bat 脚本，注意 bat 脚本必须和配置文件在一个路径，否则报错。我实现的功能是下载完成后触发一个系统通知。Linux 脚本我测试了 macos 下的脚本，使用了 AppleScript 实现，在 bash 中使用 as 可以使用 osascript 命令，脚本内容如下：#!/bin/sh
osascript -e 'display notification &quot;download complete&quot; sound name &quot;Pop.aiff&quot;'具体参考我的 osascript 教程：https://blog.niekun.net/archives/1773.htmlWindows 脚本Windows 脚本使用 powershell 实现，由于 aria2 只能调用 bat 批处理脚本，且必须在和主程序同一个目录下，所以再编写一个 bat 脚本调用 ps 脚本，稍微复杂一些。bat 脚本：script.bat@ECHO OFF

set arg1=%3

PowerShell.exe -Command &quot;&amp;'path\to\download-complete.ps1' %arg1%&quot;
PAUSEbat 脚本里传入参数使用 %0，%1，%2 等表示，%0 表示所有传入参数，%1 表示第一个参数。内部定义参数使用 set 命令，使用变量时前后加上百分号 %，如：%arg1%。以上脚本内容是：读取传入的下载文件地址参数，使用 powershell 执行 ps 脚本且传递读取的文件地址。powershell 脚本：download-complete.ps1$var1 = $args[0]

# Write-Output $var1
Add-Type -AssemblyName System.Windows.Forms
$global:balmsg = New-Object System.Windows.Forms.NotifyIcon
$path = (Get-Process -id $pid).Path
$balmsg.Icon = [System.Drawing.Icon]::ExtractAssociatedIcon($path)
$balmsg.BalloonTipIcon = [System.Windows.Forms.ToolTipIcon]::Warning
$balmsg.BalloonTipText = &quot;Path is $var1&quot;
$balmsg.BalloonTipTitle = &quot;download complete&quot;
$balmsg.Visible = $true
$balmsg.ShowBalloonTip(20000)保存以上两个脚本到 aria2.conf 配置文件一个目录下，然后修改配置文件：on-download-complete=script.bat
重新运行 aria2，下载文件测试效果。实现更多的脚本功能，可以参考开源项目：https://github.com/P3TERX/aria2.conf</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/820.html">
<title>TypechoAwesome theme for Typecho</title>
<link>https://blog.niekun.net/archives/820.html</link>
<dc:date>2019-12-19T09:55:00+08:00</dc:date>
<description>此主题是我在 typecho 原版默认主题基础上做了移动端的优化处理，适合喜欢简洁风格的人使用。typecho 是一款轻量的博客系统，风格很简洁，相比较 wordpress 占用资源很少，所以我选择了 typecho。官网：http://typecho.org/GitHub 主页：https://github.com/typecho/typecho关于 typecho 的安装参考我的教程：https://niekun.net/index.php/archives/6.html下载主题此主题是基于 typecho 最新 GitHub master 分支制作的，不保证向下兼容，请升级到最新源码后在使用此主题，升级教程参考：https://niekun.net/index.php/archives/21.htmlGitHub 主页：https://github.com/nie11kun/TypechoAwesomerelease 页面：https://github.com/nie11kun/TypechoAwesome/releases首先从 release 页面下载最新版本的源码到 typecho themes 目录：wget -O /tmp/TypechoAwesome.tar.gz https://github.com/nie11kun/TypechoAwesome/archive/V1.0.1.tar.gz
tar -zxvf /tmp/TypechoAwesome.tar.gz -C /path/to/typecho/usr/themes/
进网站后台，选择 控制台 - 外观：找到 TypechoAwesome 点击启用：然后就可以返回网站查看效果了。桌面端访问效果：移动端访问效果：移动端导航栏内容：</description>
</item>
</rdf:RDF>