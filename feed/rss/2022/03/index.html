<?xml version="1.0" encoding="UTF-8"?>
<rdf:RDF
xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
xmlns="http://purl.org/rss/1.0/"
xmlns:dc="http://purl.org/dc/elements/1.1/">
<channel rdf:about="https://blog.niekun.net/feed/rss/2022/03/">
<title>Marco Nie - 2022年3月</title>
<link>https://blog.niekun.net/2022/03/</link>
<description>you are the company you keep...</description>
<items>
<rdf:Seq>
<rdf:li resource="https://blog.niekun.net/archives/2454.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2451.html"/>
<rdf:li resource="https://blog.niekun.net/archives/2448.html"/>
</rdf:Seq>
</items>
</channel>
<item rdf:about="https://blog.niekun.net/archives/2454.html">
<title>使用 rclone 管理网盘文件</title>
<link>https://blog.niekun.net/archives/2454.html</link>
<dc:date>2022-03-14T11:35:31+08:00</dc:date>
<description>之前介绍了通过 gdrive 在服务器上管理 Google drive 文件，实现服务器数据备份自动上传功能。最近发现有一个新的开源项目 rclone 支持更多的网盘，同时更新迭代速度也更快。GitHub 主页：https://github.com/rclone/rclone他支持的网盘列表：https://rclone.org/overview/下面介绍它的安装使用方法。安装Linux 下一键安装命令：curl https://rclone.org/install.sh | sudo bash
macos 通过 brew 安装：brew install rclone
配置首次运行执行初始化配置：rclone config
根据提示创建新 remote：No remotes found - make a new one
n) New remote
r) Rename remote
c) Copy remote
s) Set configuration password
q) Quit config
n/r/c/s/q&gt; n然后设置此连接名称，后续就是通过这个名称来操作不同的网盘的：name&gt; remote
下一步选择网盘类型，如果是 Google drive 选择 16：Type of storage to configure.
Choose a number from below, or type in your own value
[snip]
16 / Google Drive
   \ &quot;drive&quot;
[snip]
Storage&gt; 16下面的 id 和 secret 都默认回车即可：Google Application Client Id - leave blank normally.
client_id&gt;
Google Application Client Secret - leave blank normally.
client_secret&gt;下面设置可访问全部网盘文件，选择 1：Scope that rclone should use when requesting access from drive.
Choose a number from below, or type in your own value
 1 / Full access all files, excluding Application Data Folder.
   \ &quot;drive&quot;
 2 / Read-only access to file metadata and file contents.
   \ &quot;drive.readonly&quot;
   / Access to files created by rclone only.
 3 | These are visible in the drive website.
   | File authorization is revoked when the user deauthorizes the app.
   \ &quot;drive.file&quot;
   / Allows read and write access to the Application Data folder.
 4 | This is not visible in the drive website.
   \ &quot;drive.appfolder&quot;
   / Allows read-only access to file metadata but
 5 | does not allow any access to read or download file content.
   \ &quot;drive.metadata.readonly&quot;
scope&gt; 1下面几步都默认回车即可。注意到了 use auto config 的时候要选择 No，因为我们是远程 ssh 访问的服务器：Use auto config?
 * Say Y if not sure
 * Say N if you are working on a remote or headless machine or Y didn't work
y) Yes
n) No
y/n&gt; n下面会返回一个链接，复制链接到浏览器后，登录 google 账户给 rclone 授权。授权完成后会返回一个字符串码，粘贴回终端。后续几步默认回车即可，最后输入 q 退出 config。使用配置完成后我们就可以使用了，下面介绍一些基本语法。下面示例中网盘配置名称为 remote。列出网盘的所有文件：rclone ls remote:
列出一个文件夹内的所有文件：rclone ls remote:abc
创建一个文件夹：rclone mkdir remote:abc
rclone mkdir remote:abc/def
删除网盘内一个文件：rclone delete remote:abc/123.txt
删除一个文件夹：rclone rmdir remote:abc
复制本地一个文件到网盘：rclone copy 123.txt remote:abc
更多可用命令可以参考官方文档：https://rclone.org/docs/#subcommands</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2451.html">
<title>Ubuntu 18.04 升级 Ubuntu 20.04 记录</title>
<link>https://blog.niekun.net/archives/2451.html</link>
<dc:date>2022-03-12T15:32:00+08:00</dc:date>
<description>昨天决定把服务器的系统从 Ubuntu 18.04 升级到 Ubuntu 20.04，其中经历了不少问题点，下面记录下处理过程。首先就是升级当前系统所有包到最新：apt update &amp;&amp; apt upgrade -y
apt autoremove &amp;&amp; apt purge
然后安装升级需要的管理包，不过一般系统都是自带的：apt install update-manager-core
然后就可以更新系统了：do-release-upgrade
标准流程就是以上几步，但是在最后一步的时候问题就开始出现了。在执行升级命令后出现报警：Failed to connect to https://changelogs.ubuntu.com/meta-release-lts. Check your Internet connection or proxy settings
在查询一些资料后，原来是 ssl certificates 验证问题，系统无法鉴定上面的 https 链接证书是否有效就返回错误了。这个问题也是我这个系统的一个遗留问题，每次执行 wget 或 curl 下载东西的时候就会提示证书报错，需要通过附加指令跳过证书验证，但这就会存在安全问题了。解决方法就是更新本地证书库后添加 SSL_CERT_DIR 环境变量指向系统证书目录：update-ca-certificates --verbose --fresh
export SSL_CERT_DIR=/etc/ssl/certs
为了方便以后使用，将环境变量添加到 ~/.bashrc 文件中。这样就解决了 https 链接证书验证问题。然后先删除之前执行升级命令后错误内容：rm /var/lib/ubuntu-release-upgrader/release-upgrade-available
/usr/lib/ubuntu-release-upgrader/release-upgrade-motd
之后再次执行升级命令 do-release-upgrade。这时候报错信息变化了，这时候提示的是 python3 有问题，原因是我当前系统使用的是自己编译的 python 3.8，路径在 /opt 目录下。当时将系统软链接 /usr/bin/python 和 /usr/bin/python3 都指向了自己安装的 python，需要将他们恢复到指向系统内置的 python 程序。下面需要介绍下系统内 python 主程序和软链接的分布：python2 主应用程序为 /usr/bin/python2.7
python3 主应用程序为 /usr/bin/python3.6
pip 主程序为 /usr/bin/pip
pip3 主程序为 /usr/bin/pip3下面是默认的软链接及指向的应用程序：/usr/bin/python  -&gt;  /usr/bin/python2.7
/usr/bin/python2  -&gt;  /usr/bin/python2.7
/usr/bin/python3  -&gt;  /usr/bin/python3.6
/usr/local/bin/pip  -&gt;  /usr/bin/pip
/usr/local/bin/pip3  -&gt;  /usr/bin/pip3如果你修改过这些软链接到自己的 python 版本，就需要修改回来：ln -sf /usr/bin/python2.7 /usr/bin/python
ln -sf /usr/bin/python2.7 /usr/bin/python2
ln -sf /usr/bin/python3.6 /usr/bin/python3
ln -sf /usr/bin/pip /usr/local/bin/pip
ln -sf /usr/bin/pip3 /usr/local/bin/pip3
ldconfig以上问题都处理完后，再次执行升级命令，一切都正常了。</description>
</item>
<item rdf:about="https://blog.niekun.net/archives/2448.html">
<title>解决 wget 下载时 certificates 证书报错问题</title>
<link>https://blog.niekun.net/archives/2448.html</link>
<dc:date>2022-03-11T16:48:00+08:00</dc:date>
<description>我的服务器上在使用 wget 或者 curl 等网络工具时，每次都提示类似下面的报错：ERROR: cannot verify github.com's certificate, issued by ‘CN=DigiCert High Assurance TLS Hybrid ECC SHA256 2020 CA1,O=DigiCert\\, Inc.,C=US’:
  Unable to locally verify the issuer's authority.
To connect to github.com insecurely, use `--no-check-certificate'.需要通过参数跳过证书检查，但是这样又有了安全风险。首先尝试更新本地证书文件：update-ca-certificates --verbose --fresh发现问题没有解决，原来是系统缺少了一个指向证书路径 /etc/ssl/certs 的环境变量，尝试添加：export SSL_CERT_DIR=/etc/ssl/certs再次测试 wget 命令，发现问题的确没有了。可以将上面的环境变量添加到系统 shell 配置文件中，我这里是 ~/.bashrc，添加后刷新一下即可：source ~/.bashrc在更新 Ubuntu18.04 到 20.04 时，也是这个问题导致的报错。</description>
</item>
</rdf:RDF>